{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x).cuda()\n",
    "        logits = self.linear_relu_stack(x).cuda()\n",
    "        return logits.cuda()\n",
    "\n",
    "model = NeuralNetwork().cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred.cuda(), y.cuda())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred.cuda(), y.cuda()).item()\n",
    "            correct += (pred.argmax(1) == y.cuda()).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.296003  [    0/60000]\n",
      "loss: 2.291049  [ 6400/60000]\n",
      "loss: 2.260320  [12800/60000]\n",
      "loss: 2.256715  [19200/60000]\n",
      "loss: 2.240220  [25600/60000]\n",
      "loss: 2.206614  [32000/60000]\n",
      "loss: 2.221170  [38400/60000]\n",
      "loss: 2.183606  [44800/60000]\n",
      "loss: 2.180608  [51200/60000]\n",
      "loss: 2.153793  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 46.5%, Avg loss: 2.141946 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.154417  [    0/60000]\n",
      "loss: 2.150961  [ 6400/60000]\n",
      "loss: 2.080471  [12800/60000]\n",
      "loss: 2.096832  [19200/60000]\n",
      "loss: 2.051881  [25600/60000]\n",
      "loss: 1.988469  [32000/60000]\n",
      "loss: 2.019925  [38400/60000]\n",
      "loss: 1.938097  [44800/60000]\n",
      "loss: 1.941316  [51200/60000]\n",
      "loss: 1.883313  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 58.8%, Avg loss: 1.866847 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.899883  [    0/60000]\n",
      "loss: 1.879504  [ 6400/60000]\n",
      "loss: 1.744996  [12800/60000]\n",
      "loss: 1.788941  [19200/60000]\n",
      "loss: 1.688334  [25600/60000]\n",
      "loss: 1.636998  [32000/60000]\n",
      "loss: 1.662141  [38400/60000]\n",
      "loss: 1.558698  [44800/60000]\n",
      "loss: 1.584185  [51200/60000]\n",
      "loss: 1.496111  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 1.500715 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.564431  [    0/60000]\n",
      "loss: 1.542857  [ 6400/60000]\n",
      "loss: 1.375848  [12800/60000]\n",
      "loss: 1.453861  [19200/60000]\n",
      "loss: 1.340416  [25600/60000]\n",
      "loss: 1.330747  [32000/60000]\n",
      "loss: 1.349751  [38400/60000]\n",
      "loss: 1.271156  [44800/60000]\n",
      "loss: 1.307961  [51200/60000]\n",
      "loss: 1.220866  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 1.240335 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.312504  [    0/60000]\n",
      "loss: 1.306929  [ 6400/60000]\n",
      "loss: 1.127632  [12800/60000]\n",
      "loss: 1.235627  [19200/60000]\n",
      "loss: 1.115286  [25600/60000]\n",
      "loss: 1.133509  [32000/60000]\n",
      "loss: 1.158162  [38400/60000]\n",
      "loss: 1.094994  [44800/60000]\n",
      "loss: 1.135837  [51200/60000]\n",
      "loss: 1.060710  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.9%, Avg loss: 1.078251 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.143763  [    0/60000]\n",
      "loss: 1.157436  [ 6400/60000]\n",
      "loss: 0.963603  [12800/60000]\n",
      "loss: 1.098327  [19200/60000]\n",
      "loss: 0.977135  [25600/60000]\n",
      "loss: 1.001109  [32000/60000]\n",
      "loss: 1.040017  [38400/60000]\n",
      "loss: 0.982565  [44800/60000]\n",
      "loss: 1.024068  [51200/60000]\n",
      "loss: 0.961571  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.973691 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.026479  [    0/60000]\n",
      "loss: 1.060657  [ 6400/60000]\n",
      "loss: 0.851206  [12800/60000]\n",
      "loss: 1.006880  [19200/60000]\n",
      "loss: 0.889977  [25600/60000]\n",
      "loss: 0.908542  [32000/60000]\n",
      "loss: 0.963042  [38400/60000]\n",
      "loss: 0.908637  [44800/60000]\n",
      "loss: 0.946977  [51200/60000]\n",
      "loss: 0.895792  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.2%, Avg loss: 0.902634 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.940476  [    0/60000]\n",
      "loss: 0.993658  [ 6400/60000]\n",
      "loss: 0.770724  [12800/60000]\n",
      "loss: 0.942665  [19200/60000]\n",
      "loss: 0.831527  [25600/60000]\n",
      "loss: 0.841741  [32000/60000]\n",
      "loss: 0.909021  [38400/60000]\n",
      "loss: 0.858589  [44800/60000]\n",
      "loss: 0.891694  [51200/60000]\n",
      "loss: 0.849185  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 0.851809 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.874788  [    0/60000]\n",
      "loss: 0.943630  [ 6400/60000]\n",
      "loss: 0.710892  [12800/60000]\n",
      "loss: 0.895384  [19200/60000]\n",
      "loss: 0.789990  [25600/60000]\n",
      "loss: 0.792424  [32000/60000]\n",
      "loss: 0.868336  [38400/60000]\n",
      "loss: 0.823198  [44800/60000]\n",
      "loss: 0.850650  [51200/60000]\n",
      "loss: 0.813918  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 0.813552 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.822909  [    0/60000]\n",
      "loss: 0.903691  [ 6400/60000]\n",
      "loss: 0.664597  [12800/60000]\n",
      "loss: 0.859034  [19200/60000]\n",
      "loss: 0.758384  [25600/60000]\n",
      "loss: 0.754920  [32000/60000]\n",
      "loss: 0.835552  [38400/60000]\n",
      "loss: 0.796862  [44800/60000]\n",
      "loss: 0.818835  [51200/60000]\n",
      "loss: 0.785947  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 0.783233 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.780386  [    0/60000]\n",
      "loss: 0.869904  [ 6400/60000]\n",
      "loss: 0.627283  [12800/60000]\n",
      "loss: 0.830036  [19200/60000]\n",
      "loss: 0.733203  [25600/60000]\n",
      "loss: 0.725638  [32000/60000]\n",
      "loss: 0.807571  [38400/60000]\n",
      "loss: 0.776065  [44800/60000]\n",
      "loss: 0.793310  [51200/60000]\n",
      "loss: 0.762890  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.1%, Avg loss: 0.758070 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.744228  [    0/60000]\n",
      "loss: 0.840237  [ 6400/60000]\n",
      "loss: 0.596339  [12800/60000]\n",
      "loss: 0.806313  [19200/60000]\n",
      "loss: 0.712126  [25600/60000]\n",
      "loss: 0.701861  [32000/60000]\n",
      "loss: 0.782571  [38400/60000]\n",
      "loss: 0.758546  [44800/60000]\n",
      "loss: 0.771851  [51200/60000]\n",
      "loss: 0.743084  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.2%, Avg loss: 0.736351 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.712795  [    0/60000]\n",
      "loss: 0.813525  [ 6400/60000]\n",
      "loss: 0.569874  [12800/60000]\n",
      "loss: 0.786141  [19200/60000]\n",
      "loss: 0.693812  [25600/60000]\n",
      "loss: 0.682067  [32000/60000]\n",
      "loss: 0.759796  [38400/60000]\n",
      "loss: 0.743257  [44800/60000]\n",
      "loss: 0.753341  [51200/60000]\n",
      "loss: 0.725528  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.717060 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.684983  [    0/60000]\n",
      "loss: 0.789093  [ 6400/60000]\n",
      "loss: 0.546936  [12800/60000]\n",
      "loss: 0.768513  [19200/60000]\n",
      "loss: 0.677713  [25600/60000]\n",
      "loss: 0.665240  [32000/60000]\n",
      "loss: 0.738833  [38400/60000]\n",
      "loss: 0.729622  [44800/60000]\n",
      "loss: 0.737162  [51200/60000]\n",
      "loss: 0.709728  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.8%, Avg loss: 0.699601 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.660153  [    0/60000]\n",
      "loss: 0.766800  [ 6400/60000]\n",
      "loss: 0.526742  [12800/60000]\n",
      "loss: 0.752826  [19200/60000]\n",
      "loss: 0.663592  [25600/60000]\n",
      "loss: 0.650702  [32000/60000]\n",
      "loss: 0.719237  [38400/60000]\n",
      "loss: 0.717398  [44800/60000]\n",
      "loss: 0.722951  [51200/60000]\n",
      "loss: 0.695308  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 0.683653 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.637901  [    0/60000]\n",
      "loss: 0.746301  [ 6400/60000]\n",
      "loss: 0.508758  [12800/60000]\n",
      "loss: 0.738603  [19200/60000]\n",
      "loss: 0.651092  [25600/60000]\n",
      "loss: 0.637973  [32000/60000]\n",
      "loss: 0.701009  [38400/60000]\n",
      "loss: 0.706443  [44800/60000]\n",
      "loss: 0.710354  [51200/60000]\n",
      "loss: 0.682131  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.669052 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.617946  [    0/60000]\n",
      "loss: 0.727416  [ 6400/60000]\n",
      "loss: 0.492671  [12800/60000]\n",
      "loss: 0.725540  [19200/60000]\n",
      "loss: 0.640040  [25600/60000]\n",
      "loss: 0.626941  [32000/60000]\n",
      "loss: 0.683921  [38400/60000]\n",
      "loss: 0.696664  [44800/60000]\n",
      "loss: 0.699177  [51200/60000]\n",
      "loss: 0.669954  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 0.655664 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.600012  [    0/60000]\n",
      "loss: 0.710106  [ 6400/60000]\n",
      "loss: 0.478169  [12800/60000]\n",
      "loss: 0.713590  [19200/60000]\n",
      "loss: 0.630175  [25600/60000]\n",
      "loss: 0.617195  [32000/60000]\n",
      "loss: 0.668028  [38400/60000]\n",
      "loss: 0.688135  [44800/60000]\n",
      "loss: 0.689313  [51200/60000]\n",
      "loss: 0.658659  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.643368 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.583764  [    0/60000]\n",
      "loss: 0.694250  [ 6400/60000]\n",
      "loss: 0.465083  [12800/60000]\n",
      "loss: 0.702554  [19200/60000]\n",
      "loss: 0.621247  [25600/60000]\n",
      "loss: 0.608625  [32000/60000]\n",
      "loss: 0.653218  [38400/60000]\n",
      "loss: 0.680861  [44800/60000]\n",
      "loss: 0.680679  [51200/60000]\n",
      "loss: 0.648168  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.632078 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.568891  [    0/60000]\n",
      "loss: 0.679614  [ 6400/60000]\n",
      "loss: 0.453335  [12800/60000]\n",
      "loss: 0.692268  [19200/60000]\n",
      "loss: 0.613121  [25600/60000]\n",
      "loss: 0.600965  [32000/60000]\n",
      "loss: 0.639560  [38400/60000]\n",
      "loss: 0.674671  [44800/60000]\n",
      "loss: 0.673121  [51200/60000]\n",
      "loss: 0.638273  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.621703 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 288x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI guess: Dress\n"
     ]
    }
   ],
   "source": [
    "labels_map={0:\"T-Shirt\",\n",
    "            1: \"Trouser\",\n",
    "            2: \"Pullover\",\n",
    "            3: \"Dress\",\n",
    "            4: \"Coat\",\n",
    "            5: \"Sandal\",\n",
    "            6: \"Shirt\",\n",
    "            7: \"Sneaker\",\n",
    "            8: \"Bag\",\n",
    "            9: \"Ankle Boot\"}\n",
    "sample_idx=torch.randint(len(training_data),size=(1,)).item()\n",
    "figure=plt.figure(figsize=(4,4))\n",
    "img,label=training_data[sample_idx]\n",
    "figure.add_subplot()\n",
    "plt.title(\"Real Label: \"+labels_map[label])\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img.squeeze(),cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "x,y=training_data[sample_idx]\n",
    "pred=model(x)\n",
    "\n",
    "maks=-100\n",
    "index=-1\n",
    "for i in range(len(pred[0])):\n",
    "    if pred[0][i]>maks:\n",
    "        maks=pred[0][i]\n",
    "        index=i\n",
    "print(\"AI guess: \"+labels_map[index])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}