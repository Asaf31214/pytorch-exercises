{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "x_values = [i for i in range(21)]\n",
    "x_train=np.array(x_values,dtype=np.float32)\n",
    "x_train = x_train.reshape(-1,1)\n",
    "y_values=[2*i+1+(np.random.rand(1)-0.5)*5 for i in x_values]\n",
    "y_train=np.array(y_values,dtype=np.float32)\n",
    "y_train=y_train.reshape(-1,1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "class linearRegression(torch.nn.Module):\n",
    "    def __init__(self,inputSize,outputSize):\n",
    "        super(linearRegression,self).__init__()\n",
    "        self.linear=torch.nn.Linear(inputSize,outputSize)\n",
    "    def forward(self,x):\n",
    "        out=self.linear(x)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "linearRegression(\n  (linear): Linear(in_features=1, out_features=1, bias=True)\n)"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputDim=1\n",
    "outputDim=1\n",
    "learningRate=0.0001\n",
    "epochs=1000\n",
    "model =linearRegression(inputDim,outputDim)\n",
    "model.cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "criterion=torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=learningRate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(197.7075, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 0, loss 197.70750427246094\n",
      "tensor(187.1721, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 1, loss 187.17205810546875\n",
      "tensor(177.2077, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 2, loss 177.2076873779297\n",
      "tensor(167.7834, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 3, loss 167.78338623046875\n",
      "tensor(158.8700, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 4, loss 158.86996459960938\n",
      "tensor(150.4396, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 5, loss 150.43963623046875\n",
      "tensor(142.4663, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 6, loss 142.46629333496094\n",
      "tensor(134.9252, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 7, loss 134.92515563964844\n",
      "tensor(127.7928, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 8, loss 127.79276275634766\n",
      "tensor(121.0470, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 9, loss 121.04695892333984\n",
      "tensor(114.6668, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 10, loss 114.66681671142578\n",
      "tensor(108.6325, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 11, loss 108.63249969482422\n",
      "tensor(102.9253, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 12, loss 102.92526245117188\n",
      "tensor(97.5274, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 13, loss 97.5273666381836\n",
      "tensor(92.4221, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 14, loss 92.42205047607422\n",
      "tensor(87.5935, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 15, loss 87.59347534179688\n",
      "tensor(83.0266, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 16, loss 83.02662658691406\n",
      "tensor(78.7073, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 17, loss 78.7072982788086\n",
      "tensor(74.6221, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 18, loss 74.62210845947266\n",
      "tensor(70.7583, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 19, loss 70.75833892822266\n",
      "tensor(67.1040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 20, loss 67.10399627685547\n",
      "tensor(63.6477, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 21, loss 63.64773941040039\n",
      "tensor(60.3788, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 22, loss 60.37880325317383\n",
      "tensor(57.2871, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 23, loss 57.28706359863281\n",
      "tensor(54.3629, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 24, loss 54.36289978027344\n",
      "tensor(51.5972, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 25, loss 51.59724044799805\n",
      "tensor(48.9815, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 26, loss 48.981468200683594\n",
      "tensor(46.5075, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 27, loss 46.50748062133789\n",
      "tensor(44.1676, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 28, loss 44.1676025390625\n",
      "tensor(41.9545, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 29, loss 41.95454788208008\n",
      "tensor(39.8614, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 30, loss 39.86143112182617\n",
      "tensor(37.8818, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 31, loss 37.88175964355469\n",
      "tensor(36.0094, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 32, loss 36.009395599365234\n",
      "tensor(34.2385, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 33, loss 34.23851776123047\n",
      "tensor(32.5636, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 34, loss 32.563629150390625\n",
      "tensor(30.9795, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 35, loss 30.979503631591797\n",
      "tensor(29.4813, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 36, loss 29.481250762939453\n",
      "tensor(28.0642, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 37, loss 28.06419563293457\n",
      "tensor(26.7239, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 38, loss 26.723947525024414\n",
      "tensor(25.4563, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 39, loss 25.456342697143555\n",
      "tensor(24.2574, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 40, loss 24.257436752319336\n",
      "tensor(23.1235, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 41, loss 23.123510360717773\n",
      "tensor(22.0510, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 42, loss 22.051048278808594\n",
      "tensor(21.0367, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 43, loss 21.036705017089844\n",
      "tensor(20.0773, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 44, loss 20.077335357666016\n",
      "tensor(19.1700, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 45, loss 19.169967651367188\n",
      "tensor(18.3118, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 46, loss 18.311777114868164\n",
      "tensor(17.5001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 47, loss 17.50008773803711\n",
      "tensor(16.7324, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 48, loss 16.73240089416504\n",
      "tensor(16.0063, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 49, loss 16.00631332397461\n",
      "tensor(15.3196, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 50, loss 15.319574356079102\n",
      "tensor(14.6700, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 51, loss 14.67004680633545\n",
      "tensor(14.0557, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 52, loss 14.055727005004883\n",
      "tensor(13.4747, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 53, loss 13.474692344665527\n",
      "tensor(12.9251, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 54, loss 12.925148963928223\n",
      "tensor(12.4054, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 55, loss 12.405381202697754\n",
      "tensor(11.9138, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 56, loss 11.913785934448242\n",
      "tensor(11.4488, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 57, loss 11.448829650878906\n",
      "tensor(11.0091, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 58, loss 11.009065628051758\n",
      "tensor(10.5931, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 59, loss 10.593132972717285\n",
      "tensor(10.1997, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 60, loss 10.199737548828125\n",
      "tensor(9.8277, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 61, loss 9.82766342163086\n",
      "tensor(9.4757, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 62, loss 9.475749969482422\n",
      "tensor(9.1429, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 63, loss 9.14290714263916\n",
      "tensor(8.8281, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 64, loss 8.828094482421875\n",
      "tensor(8.5303, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 65, loss 8.530336380004883\n",
      "tensor(8.2487, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 66, loss 8.248710632324219\n",
      "tensor(7.9823, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 67, loss 7.982346534729004\n",
      "tensor(7.7304, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 68, loss 7.730412006378174\n",
      "tensor(7.4921, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 69, loss 7.49212646484375\n",
      "tensor(7.2667, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 70, loss 7.266746997833252\n",
      "tensor(7.0536, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 71, loss 7.053577423095703\n",
      "tensor(6.8520, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 72, loss 6.851960182189941\n",
      "tensor(6.6613, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 73, loss 6.661262035369873\n",
      "tensor(6.4809, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 74, loss 6.480891704559326\n",
      "tensor(6.3103, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 75, loss 6.310291290283203\n",
      "tensor(6.1489, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 76, loss 6.148932456970215\n",
      "tensor(5.9963, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 77, loss 5.996309757232666\n",
      "tensor(5.8520, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 78, loss 5.8519511222839355\n",
      "tensor(5.7154, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 79, loss 5.715411186218262\n",
      "tensor(5.5863, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 80, loss 5.586269855499268\n",
      "tensor(5.4641, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 81, loss 5.464113235473633\n",
      "tensor(5.3486, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 82, loss 5.348577499389648\n",
      "tensor(5.2393, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 83, loss 5.2392964363098145\n",
      "tensor(5.1359, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 84, loss 5.135926246643066\n",
      "tensor(5.0382, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 85, loss 5.0381550788879395\n",
      "tensor(4.9457, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 86, loss 4.945676803588867\n",
      "tensor(4.8582, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 87, loss 4.858206272125244\n",
      "tensor(4.7755, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 88, loss 4.775469779968262\n",
      "tensor(4.6972, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 89, loss 4.697206497192383\n",
      "tensor(4.6232, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 90, loss 4.6231794357299805\n",
      "tensor(4.5532, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 91, loss 4.553162574768066\n",
      "tensor(4.4869, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 92, loss 4.4869303703308105\n",
      "tensor(4.4243, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 93, loss 4.424281120300293\n",
      "tensor(4.3650, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 94, loss 4.365021705627441\n",
      "tensor(4.3090, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 95, loss 4.308964729309082\n",
      "tensor(4.2559, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 96, loss 4.255939960479736\n",
      "tensor(4.2058, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 97, loss 4.205782413482666\n",
      "tensor(4.1583, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 98, loss 4.158336162567139\n",
      "tensor(4.1135, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 99, loss 4.113454818725586\n",
      "tensor(4.0710, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 100, loss 4.070996284484863\n",
      "tensor(4.0308, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 101, loss 4.030835151672363\n",
      "tensor(3.9928, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 102, loss 3.9928414821624756\n",
      "tensor(3.9569, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 103, loss 3.956899404525757\n",
      "tensor(3.9229, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 104, loss 3.9228978157043457\n",
      "tensor(3.8907, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 105, loss 3.8907315731048584\n",
      "tensor(3.8603, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 106, loss 3.860304832458496\n",
      "tensor(3.8315, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 107, loss 3.83151912689209\n",
      "tensor(3.8043, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 108, loss 3.804285764694214\n",
      "tensor(3.7785, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 109, loss 3.7785184383392334\n",
      "tensor(3.7541, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 110, loss 3.7541439533233643\n",
      "tensor(3.7311, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 111, loss 3.7310831546783447\n",
      "tensor(3.7093, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 112, loss 3.7092645168304443\n",
      "tensor(3.6886, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 113, loss 3.6886227130889893\n",
      "tensor(3.6691, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 114, loss 3.6690893173217773\n",
      "tensor(3.6506, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 115, loss 3.65061092376709\n",
      "tensor(3.6331, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 116, loss 3.6331231594085693\n",
      "tensor(3.6166, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 117, loss 3.6165785789489746\n",
      "tensor(3.6009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 118, loss 3.6009223461151123\n",
      "tensor(3.5861, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 119, loss 3.5861082077026367\n",
      "tensor(3.5721, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 120, loss 3.572089910507202\n",
      "tensor(3.5588, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 121, loss 3.5588245391845703\n",
      "tensor(3.5463, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 122, loss 3.5462701320648193\n",
      "tensor(3.5344, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 123, loss 3.534390449523926\n",
      "tensor(3.5231, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 124, loss 3.523145914077759\n",
      "tensor(3.5125, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 125, loss 3.512502908706665\n",
      "tensor(3.5024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 126, loss 3.502431631088257\n",
      "tensor(3.4929, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 127, loss 3.4928975105285645\n",
      "tensor(3.4839, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 128, loss 3.483872175216675\n",
      "tensor(3.4753, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 129, loss 3.475327968597412\n",
      "tensor(3.4672, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 130, loss 3.4672415256500244\n",
      "tensor(3.4596, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 131, loss 3.4595847129821777\n",
      "tensor(3.4523, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 132, loss 3.452336311340332\n",
      "tensor(3.4455, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 133, loss 3.445474863052368\n",
      "tensor(3.4390, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 134, loss 3.438977003097534\n",
      "tensor(3.4328, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 135, loss 3.4328243732452393\n",
      "tensor(3.4270, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 136, loss 3.4269983768463135\n",
      "tensor(3.4215, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 137, loss 3.421480417251587\n",
      "tensor(3.4163, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 138, loss 3.4162540435791016\n",
      "tensor(3.4113, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 139, loss 3.4113035202026367\n",
      "tensor(3.4066, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 140, loss 3.406614065170288\n",
      "tensor(3.4022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 141, loss 3.4021711349487305\n",
      "tensor(3.3980, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 142, loss 3.3979623317718506\n",
      "tensor(3.3940, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 143, loss 3.3939740657806396\n",
      "tensor(3.3902, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 144, loss 3.390194892883301\n",
      "tensor(3.3866, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 145, loss 3.3866140842437744\n",
      "tensor(3.3832, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 146, loss 3.3832201957702637\n",
      "tensor(3.3800, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 147, loss 3.3800013065338135\n",
      "tensor(3.3770, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 148, loss 3.3769516944885254\n",
      "tensor(3.3741, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 149, loss 3.374058485031128\n",
      "tensor(3.3713, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 150, loss 3.3713154792785645\n",
      "tensor(3.3687, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 151, loss 3.368711233139038\n",
      "tensor(3.3662, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 152, loss 3.366243600845337\n",
      "tensor(3.3639, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 153, loss 3.3639025688171387\n",
      "tensor(3.3617, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 154, loss 3.361679792404175\n",
      "tensor(3.3596, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 155, loss 3.359571695327759\n",
      "tensor(3.3576, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 156, loss 3.3575680255889893\n",
      "tensor(3.3557, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 157, loss 3.355668544769287\n",
      "tensor(3.3539, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 158, loss 3.353863477706909\n",
      "tensor(3.3521, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 159, loss 3.35214900970459\n",
      "tensor(3.3505, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 160, loss 3.350519895553589\n",
      "tensor(3.3490, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 161, loss 3.3489718437194824\n",
      "tensor(3.3475, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 162, loss 3.347500801086426\n",
      "tensor(3.3461, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 163, loss 3.3461034297943115\n",
      "tensor(3.3448, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 164, loss 3.344773054122925\n",
      "tensor(3.3435, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 165, loss 3.3435072898864746\n",
      "tensor(3.3423, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 166, loss 3.3423025608062744\n",
      "tensor(3.3412, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 167, loss 3.3411574363708496\n",
      "tensor(3.3401, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 168, loss 3.3400676250457764\n",
      "tensor(3.3390, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 169, loss 3.3390285968780518\n",
      "tensor(3.3380, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 170, loss 3.3380374908447266\n",
      "tensor(3.3371, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 171, loss 3.337094306945801\n",
      "tensor(3.3362, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 172, loss 3.336193323135376\n",
      "tensor(3.3353, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 173, loss 3.3353359699249268\n",
      "tensor(3.3345, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 174, loss 3.3345162868499756\n",
      "tensor(3.3337, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 175, loss 3.333735227584839\n",
      "tensor(3.3330, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 176, loss 3.3329882621765137\n",
      "tensor(3.3323, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 177, loss 3.332273244857788\n",
      "tensor(3.3316, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 178, loss 3.3315916061401367\n",
      "tensor(3.3309, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 179, loss 3.3309409618377686\n",
      "tensor(3.3303, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 180, loss 3.330315113067627\n",
      "tensor(3.3297, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 181, loss 3.3297181129455566\n",
      "tensor(3.3291, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 182, loss 3.329145908355713\n",
      "tensor(3.3286, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 183, loss 3.328596353530884\n",
      "tensor(3.3281, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 184, loss 3.3280701637268066\n",
      "tensor(3.3276, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 185, loss 3.327565908432007\n",
      "tensor(3.3271, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 186, loss 3.3270809650421143\n",
      "tensor(3.3266, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 187, loss 3.326613426208496\n",
      "tensor(3.3262, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 188, loss 3.326166868209839\n",
      "tensor(3.3257, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 189, loss 3.325735330581665\n",
      "tensor(3.3253, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 190, loss 3.3253209590911865\n",
      "tensor(3.3249, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 191, loss 3.324920654296875\n",
      "tensor(3.3245, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 192, loss 3.324535608291626\n",
      "tensor(3.3242, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 193, loss 3.324165105819702\n",
      "tensor(3.3238, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 194, loss 3.323805332183838\n",
      "tensor(3.3235, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 195, loss 3.323458671569824\n",
      "tensor(3.3231, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 196, loss 3.323124647140503\n",
      "tensor(3.3228, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 197, loss 3.3228001594543457\n",
      "tensor(3.3225, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 198, loss 3.3224873542785645\n",
      "tensor(3.3222, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 199, loss 3.3221821784973145\n",
      "tensor(3.3219, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 200, loss 3.3218870162963867\n",
      "tensor(3.3216, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 201, loss 3.3216018676757812\n",
      "tensor(3.3213, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 202, loss 3.3213231563568115\n",
      "tensor(3.3211, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 203, loss 3.3210530281066895\n",
      "tensor(3.3208, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 204, loss 3.3207929134368896\n",
      "tensor(3.3205, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 205, loss 3.320535659790039\n",
      "tensor(3.3203, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 206, loss 3.3202879428863525\n",
      "tensor(3.3200, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 207, loss 3.320045232772827\n",
      "tensor(3.3198, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 208, loss 3.319807291030884\n",
      "tensor(3.3196, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 209, loss 3.319577217102051\n",
      "tensor(3.3194, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 210, loss 3.3193511962890625\n",
      "tensor(3.3191, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 211, loss 3.3191299438476562\n",
      "tensor(3.3189, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 212, loss 3.3189139366149902\n",
      "tensor(3.3187, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 213, loss 3.318702459335327\n",
      "tensor(3.3185, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 214, loss 3.318495273590088\n",
      "tensor(3.3183, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 215, loss 3.318291187286377\n",
      "tensor(3.3181, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 216, loss 3.3180923461914062\n",
      "tensor(3.3179, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 217, loss 3.3178954124450684\n",
      "tensor(3.3177, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 218, loss 3.3177037239074707\n",
      "tensor(3.3175, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 219, loss 3.317514419555664\n",
      "tensor(3.3173, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 220, loss 3.3173277378082275\n",
      "tensor(3.3171, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 221, loss 3.3171441555023193\n",
      "tensor(3.3170, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 222, loss 3.3169636726379395\n",
      "tensor(3.3168, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 223, loss 3.316786289215088\n",
      "tensor(3.3166, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 224, loss 3.31661057472229\n",
      "tensor(3.3164, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 225, loss 3.3164353370666504\n",
      "tensor(3.3163, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 226, loss 3.316265344619751\n",
      "tensor(3.3161, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 227, loss 3.3160953521728516\n",
      "tensor(3.3159, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 228, loss 3.3159282207489014\n",
      "tensor(3.3158, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 229, loss 3.315762519836426\n",
      "tensor(3.3156, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 230, loss 3.315598964691162\n",
      "tensor(3.3154, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 231, loss 3.3154373168945312\n",
      "tensor(3.3153, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 232, loss 3.315277099609375\n",
      "tensor(3.3151, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 233, loss 3.315117359161377\n",
      "tensor(3.3150, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 234, loss 3.314960241317749\n",
      "tensor(3.3148, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 235, loss 3.3148040771484375\n",
      "tensor(3.3146, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 236, loss 3.314649820327759\n",
      "tensor(3.3145, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 237, loss 3.3144941329956055\n",
      "tensor(3.3143, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 238, loss 3.3143420219421387\n",
      "tensor(3.3142, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 239, loss 3.3141913414001465\n",
      "tensor(3.3140, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 240, loss 3.3140408992767334\n",
      "tensor(3.3139, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 241, loss 3.3138904571533203\n",
      "tensor(3.3137, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 242, loss 3.3137428760528564\n",
      "tensor(3.3136, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 243, loss 3.313593626022339\n",
      "tensor(3.3134, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 244, loss 3.3134467601776123\n",
      "tensor(3.3133, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 245, loss 3.313300132751465\n",
      "tensor(3.3132, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 246, loss 3.313154697418213\n",
      "tensor(3.3130, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 247, loss 3.3130102157592773\n",
      "tensor(3.3129, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 248, loss 3.3128652572631836\n",
      "tensor(3.3127, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 249, loss 3.3127219676971436\n",
      "tensor(3.3126, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 250, loss 3.3125789165496826\n",
      "tensor(3.3124, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 251, loss 3.312436103820801\n",
      "tensor(3.3123, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 252, loss 3.312293767929077\n",
      "tensor(3.3122, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 253, loss 3.3121531009674072\n",
      "tensor(3.3120, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 254, loss 3.31201171875\n",
      "tensor(3.3119, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 255, loss 3.3118720054626465\n",
      "tensor(3.3117, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 256, loss 3.311732053756714\n",
      "tensor(3.3116, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 257, loss 3.3115925788879395\n",
      "tensor(3.3115, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 258, loss 3.3114523887634277\n",
      "tensor(3.3113, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 259, loss 3.3113133907318115\n",
      "tensor(3.3112, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 260, loss 3.3111746311187744\n",
      "tensor(3.3110, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 261, loss 3.3110358715057373\n",
      "tensor(3.3109, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 262, loss 3.3108975887298584\n",
      "tensor(3.3108, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 263, loss 3.3107597827911377\n",
      "tensor(3.3106, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 264, loss 3.310622453689575\n",
      "tensor(3.3105, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 265, loss 3.3104851245880127\n",
      "tensor(3.3103, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 266, loss 3.3103485107421875\n",
      "tensor(3.3102, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 267, loss 3.310211658477783\n",
      "tensor(3.3101, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 268, loss 3.3100759983062744\n",
      "tensor(3.3099, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 269, loss 3.309939384460449\n",
      "tensor(3.3098, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 270, loss 3.309802770614624\n",
      "tensor(3.3097, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 271, loss 3.3096680641174316\n",
      "tensor(3.3095, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 272, loss 3.30953049659729\n",
      "tensor(3.3094, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 273, loss 3.3093960285186768\n",
      "tensor(3.3093, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 274, loss 3.3092594146728516\n",
      "tensor(3.3091, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 275, loss 3.3091237545013428\n",
      "tensor(3.3090, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 276, loss 3.3089897632598877\n",
      "tensor(3.3089, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 277, loss 3.308854579925537\n",
      "tensor(3.3087, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 278, loss 3.308720350265503\n",
      "tensor(3.3086, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 279, loss 3.308584690093994\n",
      "tensor(3.3084, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 280, loss 3.3084499835968018\n",
      "tensor(3.3083, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 281, loss 3.308316230773926\n",
      "tensor(3.3082, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 282, loss 3.30818247795105\n",
      "tensor(3.3080, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 283, loss 3.308046579360962\n",
      "tensor(3.3079, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 284, loss 3.307913303375244\n",
      "tensor(3.3078, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 285, loss 3.3077800273895264\n",
      "tensor(3.3076, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 286, loss 3.307644844055176\n",
      "tensor(3.3075, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 287, loss 3.3075110912323\n",
      "tensor(3.3074, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 288, loss 3.3073763847351074\n",
      "tensor(3.3072, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 289, loss 3.3072431087493896\n",
      "tensor(3.3071, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 290, loss 3.307110548019409\n",
      "tensor(3.3070, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 291, loss 3.3069770336151123\n",
      "tensor(3.3068, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 292, loss 3.306842565536499\n",
      "tensor(3.3067, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 293, loss 3.306709051132202\n",
      "tensor(3.3066, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 294, loss 3.3065760135650635\n",
      "tensor(3.3064, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 295, loss 3.3064422607421875\n",
      "tensor(3.3063, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 296, loss 3.306309461593628\n",
      "tensor(3.3062, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 297, loss 3.3061764240264893\n",
      "tensor(3.3060, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 298, loss 3.3060433864593506\n",
      "tensor(3.3059, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 299, loss 3.3059096336364746\n",
      "tensor(3.3058, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 300, loss 3.3057775497436523\n",
      "tensor(3.3056, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 301, loss 3.3056445121765137\n",
      "tensor(3.3055, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 302, loss 3.3055107593536377\n",
      "tensor(3.3054, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 303, loss 3.305377721786499\n",
      "tensor(3.3052, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 304, loss 3.305244207382202\n",
      "tensor(3.3051, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 305, loss 3.305112600326538\n",
      "tensor(3.3050, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 306, loss 3.3049793243408203\n",
      "tensor(3.3048, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 307, loss 3.3048460483551025\n",
      "tensor(3.3047, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 308, loss 3.304713249206543\n",
      "tensor(3.3046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 309, loss 3.3045806884765625\n",
      "tensor(3.3044, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 310, loss 3.3044493198394775\n",
      "tensor(3.3043, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 311, loss 3.3043155670166016\n",
      "tensor(3.3042, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 312, loss 3.3041832447052\n",
      "tensor(3.3041, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 313, loss 3.3040502071380615\n",
      "tensor(3.3039, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 314, loss 3.3039188385009766\n",
      "tensor(3.3038, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 315, loss 3.3037850856781006\n",
      "tensor(3.3037, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 316, loss 3.3036539554595947\n",
      "tensor(3.3035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 317, loss 3.303520679473877\n",
      "tensor(3.3034, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 318, loss 3.303389072418213\n",
      "tensor(3.3033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 319, loss 3.3032565116882324\n",
      "tensor(3.3031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 320, loss 3.303123950958252\n",
      "tensor(3.3030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 321, loss 3.3029916286468506\n",
      "tensor(3.3029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 322, loss 3.3028597831726074\n",
      "tensor(3.3027, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 323, loss 3.3027260303497314\n",
      "tensor(3.3026, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 324, loss 3.3025946617126465\n",
      "tensor(3.3025, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 325, loss 3.302462577819824\n",
      "tensor(3.3023, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 326, loss 3.3023297786712646\n",
      "tensor(3.3022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 327, loss 3.302198648452759\n",
      "tensor(3.3021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 328, loss 3.302065849304199\n",
      "tensor(3.3019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 329, loss 3.3019330501556396\n",
      "tensor(3.3018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 330, loss 3.3018014430999756\n",
      "tensor(3.3017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 331, loss 3.3016698360443115\n",
      "tensor(3.3015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 332, loss 3.3015377521514893\n",
      "tensor(3.3014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 333, loss 3.301406145095825\n",
      "tensor(3.3013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 334, loss 3.3012728691101074\n",
      "tensor(3.3011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 335, loss 3.3011410236358643\n",
      "tensor(3.3010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 336, loss 3.301008462905884\n",
      "tensor(3.3009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 337, loss 3.3008763790130615\n",
      "tensor(3.3007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 338, loss 3.3007452487945557\n",
      "tensor(3.3006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 339, loss 3.3006134033203125\n",
      "tensor(3.3005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 340, loss 3.3004813194274902\n",
      "tensor(3.3003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 341, loss 3.3003499507904053\n",
      "tensor(3.3002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 342, loss 3.300218105316162\n",
      "tensor(3.3001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 343, loss 3.3000848293304443\n",
      "tensor(3.3000, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 344, loss 3.299954414367676\n",
      "tensor(3.2998, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 345, loss 3.2998220920562744\n",
      "tensor(3.2997, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 346, loss 3.299689531326294\n",
      "tensor(3.2996, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 347, loss 3.299557685852051\n",
      "tensor(3.2994, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 348, loss 3.2994260787963867\n",
      "tensor(3.2993, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 349, loss 3.2992942333221436\n",
      "tensor(3.2992, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 350, loss 3.2991621494293213\n",
      "tensor(3.2990, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 351, loss 3.299030065536499\n",
      "tensor(3.2989, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 352, loss 3.298898696899414\n",
      "tensor(3.2988, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 353, loss 3.2987678050994873\n",
      "tensor(3.2986, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 354, loss 3.2986342906951904\n",
      "tensor(3.2985, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 355, loss 3.298504114151001\n",
      "tensor(3.2984, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 356, loss 3.2983717918395996\n",
      "tensor(3.2982, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 357, loss 3.2982404232025146\n",
      "tensor(3.2981, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 358, loss 3.298107385635376\n",
      "tensor(3.2980, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 359, loss 3.2979772090911865\n",
      "tensor(3.2978, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 360, loss 3.297844409942627\n",
      "tensor(3.2977, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 361, loss 3.297713279724121\n",
      "tensor(3.2976, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 362, loss 3.2975828647613525\n",
      "tensor(3.2974, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 363, loss 3.2974493503570557\n",
      "tensor(3.2973, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 364, loss 3.2973179817199707\n",
      "tensor(3.2972, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 365, loss 3.297187566757202\n",
      "tensor(3.2971, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 366, loss 3.2970564365386963\n",
      "tensor(3.2969, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 367, loss 3.296924114227295\n",
      "tensor(3.2968, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 368, loss 3.296792507171631\n",
      "tensor(3.2967, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 369, loss 3.2966606616973877\n",
      "tensor(3.2965, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 370, loss 3.296530246734619\n",
      "tensor(3.2964, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 371, loss 3.2963969707489014\n",
      "tensor(3.2963, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 372, loss 3.2962658405303955\n",
      "tensor(3.2961, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 373, loss 3.2961342334747314\n",
      "tensor(3.2960, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 374, loss 3.2960028648376465\n",
      "tensor(3.2959, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 375, loss 3.295872449874878\n",
      "tensor(3.2957, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 376, loss 3.295741558074951\n",
      "tensor(3.2956, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 377, loss 3.295609951019287\n",
      "tensor(3.2955, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 378, loss 3.2954792976379395\n",
      "tensor(3.2953, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 379, loss 3.2953476905822754\n",
      "tensor(3.2952, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 380, loss 3.2952163219451904\n",
      "tensor(3.2951, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 381, loss 3.2950847148895264\n",
      "tensor(3.2950, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 382, loss 3.2949535846710205\n",
      "tensor(3.2948, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 383, loss 3.2948224544525146\n",
      "tensor(3.2947, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 384, loss 3.2946901321411133\n",
      "tensor(3.2946, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 385, loss 3.2945590019226074\n",
      "tensor(3.2944, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 386, loss 3.2944278717041016\n",
      "tensor(3.2943, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 387, loss 3.2942962646484375\n",
      "tensor(3.2942, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 388, loss 3.2941651344299316\n",
      "tensor(3.2940, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 389, loss 3.294034004211426\n",
      "tensor(3.2939, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 390, loss 3.2939040660858154\n",
      "tensor(3.2938, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 391, loss 3.2937724590301514\n",
      "tensor(3.2936, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 392, loss 3.293640613555908\n",
      "tensor(3.2935, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 393, loss 3.2935104370117188\n",
      "tensor(3.2934, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 394, loss 3.2933785915374756\n",
      "tensor(3.2932, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 395, loss 3.293248176574707\n",
      "tensor(3.2931, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 396, loss 3.293116331100464\n",
      "tensor(3.2930, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 397, loss 3.2929847240448\n",
      "tensor(3.2929, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 398, loss 3.292853355407715\n",
      "tensor(3.2927, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 399, loss 3.2927238941192627\n",
      "tensor(3.2926, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 400, loss 3.2925918102264404\n",
      "tensor(3.2925, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 401, loss 3.2924604415893555\n",
      "tensor(3.2923, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 402, loss 3.292329788208008\n",
      "tensor(3.2922, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 403, loss 3.2921993732452393\n",
      "tensor(3.2921, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 404, loss 3.292067766189575\n",
      "tensor(3.2919, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 405, loss 3.2919371128082275\n",
      "tensor(3.2918, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 406, loss 3.2918059825897217\n",
      "tensor(3.2917, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 407, loss 3.291675329208374\n",
      "tensor(3.2915, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 408, loss 3.291544198989868\n",
      "tensor(3.2914, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 409, loss 3.2914137840270996\n",
      "tensor(3.2913, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 410, loss 3.291283130645752\n",
      "tensor(3.2912, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 411, loss 3.291151285171509\n",
      "tensor(3.2910, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 412, loss 3.291020154953003\n",
      "tensor(3.2909, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 413, loss 3.2908895015716553\n",
      "tensor(3.2908, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 414, loss 3.290757656097412\n",
      "tensor(3.2906, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 415, loss 3.290627956390381\n",
      "tensor(3.2905, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 416, loss 3.2904961109161377\n",
      "tensor(3.2904, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 417, loss 3.29036545753479\n",
      "tensor(3.2902, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 418, loss 3.2902350425720215\n",
      "tensor(3.2901, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 419, loss 3.290104866027832\n",
      "tensor(3.2900, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 420, loss 3.289975166320801\n",
      "tensor(3.2898, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 421, loss 3.2898428440093994\n",
      "tensor(3.2897, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 422, loss 3.289712905883789\n",
      "tensor(3.2896, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 423, loss 3.2895824909210205\n",
      "tensor(3.2895, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 424, loss 3.2894513607025146\n",
      "tensor(3.2893, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 425, loss 3.2893197536468506\n",
      "tensor(3.2892, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 426, loss 3.2891905307769775\n",
      "tensor(3.2891, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 427, loss 3.2890584468841553\n",
      "tensor(3.2889, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 428, loss 3.288928508758545\n",
      "tensor(3.2888, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 429, loss 3.288797378540039\n",
      "tensor(3.2887, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 430, loss 3.288667678833008\n",
      "tensor(3.2885, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 431, loss 3.2885358333587646\n",
      "tensor(3.2884, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 432, loss 3.2884063720703125\n",
      "tensor(3.2883, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 433, loss 3.2882742881774902\n",
      "tensor(3.2881, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 434, loss 3.288144826889038\n",
      "tensor(3.2880, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 435, loss 3.288013219833374\n",
      "tensor(3.2879, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 436, loss 3.287883996963501\n",
      "tensor(3.2878, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 437, loss 3.287752389907837\n",
      "tensor(3.2876, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 438, loss 3.287623167037964\n",
      "tensor(3.2875, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 439, loss 3.2874915599823\n",
      "tensor(3.2874, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 440, loss 3.2873623371124268\n",
      "tensor(3.2872, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 441, loss 3.2872304916381836\n",
      "tensor(3.2871, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 442, loss 3.2871007919311523\n",
      "tensor(3.2870, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 443, loss 3.2869699001312256\n",
      "tensor(3.2868, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 444, loss 3.2868402004241943\n",
      "tensor(3.2867, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 445, loss 3.286709785461426\n",
      "tensor(3.2866, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 446, loss 3.28657865524292\n",
      "tensor(3.2864, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 447, loss 3.2864491939544678\n",
      "tensor(3.2863, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 448, loss 3.2863166332244873\n",
      "tensor(3.2862, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 449, loss 3.286186695098877\n",
      "tensor(3.2861, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 450, loss 3.2860562801361084\n",
      "tensor(3.2859, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 451, loss 3.2859280109405518\n",
      "tensor(3.2858, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 452, loss 3.285797595977783\n",
      "tensor(3.2857, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 453, loss 3.2856667041778564\n",
      "tensor(3.2855, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 454, loss 3.285537004470825\n",
      "tensor(3.2854, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 455, loss 3.2854056358337402\n",
      "tensor(3.2853, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 456, loss 3.285275459289551\n",
      "tensor(3.2851, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 457, loss 3.2851450443267822\n",
      "tensor(3.2850, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 458, loss 3.2850148677825928\n",
      "tensor(3.2849, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 459, loss 3.2848851680755615\n",
      "tensor(3.2848, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 460, loss 3.284754514694214\n",
      "tensor(3.2846, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 461, loss 3.2846243381500244\n",
      "tensor(3.2845, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 462, loss 3.2844936847686768\n",
      "tensor(3.2844, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 463, loss 3.284363269805908\n",
      "tensor(3.2842, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 464, loss 3.2842345237731934\n",
      "tensor(3.2841, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 465, loss 3.2841033935546875\n",
      "tensor(3.2840, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 466, loss 3.283973455429077\n",
      "tensor(3.2838, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 467, loss 3.2838425636291504\n",
      "tensor(3.2837, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 468, loss 3.28371262550354\n",
      "tensor(3.2836, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 469, loss 3.283582925796509\n",
      "tensor(3.2835, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 470, loss 3.2834532260894775\n",
      "tensor(3.2833, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 471, loss 3.2833235263824463\n",
      "tensor(3.2832, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 472, loss 3.2831931114196777\n",
      "tensor(3.2831, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 473, loss 3.2830634117126465\n",
      "tensor(3.2829, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 474, loss 3.2829320430755615\n",
      "tensor(3.2828, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 475, loss 3.282803535461426\n",
      "tensor(3.2827, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 476, loss 3.282672643661499\n",
      "tensor(3.2825, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 477, loss 3.2825427055358887\n",
      "tensor(3.2824, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 478, loss 3.282412528991699\n",
      "tensor(3.2823, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 479, loss 3.282282590866089\n",
      "tensor(3.2822, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 480, loss 3.2821531295776367\n",
      "tensor(3.2820, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 481, loss 3.2820239067077637\n",
      "tensor(3.2819, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 482, loss 3.281893014907837\n",
      "tensor(3.2818, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 483, loss 3.281763792037964\n",
      "tensor(3.2816, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 484, loss 3.281632900238037\n",
      "tensor(3.2815, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 485, loss 3.281503200531006\n",
      "tensor(3.2814, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 486, loss 3.281374216079712\n",
      "tensor(3.2812, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 487, loss 3.281244993209839\n",
      "tensor(3.2811, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 488, loss 3.281113386154175\n",
      "tensor(3.2810, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 489, loss 3.2809836864471436\n",
      "tensor(3.2809, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 490, loss 3.280853271484375\n",
      "tensor(3.2807, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 491, loss 3.2807254791259766\n",
      "tensor(3.2806, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 492, loss 3.280593156814575\n",
      "tensor(3.2805, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 493, loss 3.2804646492004395\n",
      "tensor(3.2803, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 494, loss 3.280334234237671\n",
      "tensor(3.2802, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 495, loss 3.2802059650421143\n",
      "tensor(3.2801, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 496, loss 3.2800769805908203\n",
      "tensor(3.2799, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 497, loss 3.2799458503723145\n",
      "tensor(3.2798, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 498, loss 3.279815673828125\n",
      "tensor(3.2797, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 499, loss 3.2796874046325684\n",
      "tensor(3.2796, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 500, loss 3.2795569896698\n",
      "tensor(3.2794, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 501, loss 3.279428005218506\n",
      "tensor(3.2793, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 502, loss 3.279297351837158\n",
      "tensor(3.2792, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 503, loss 3.279167890548706\n",
      "tensor(3.2790, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 504, loss 3.2790374755859375\n",
      "tensor(3.2789, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 505, loss 3.2789089679718018\n",
      "tensor(3.2788, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 506, loss 3.2787792682647705\n",
      "tensor(3.2786, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 507, loss 3.278648853302002\n",
      "tensor(3.2785, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 508, loss 3.2785208225250244\n",
      "tensor(3.2784, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 509, loss 3.2783901691436768\n",
      "tensor(3.2783, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 510, loss 3.2782607078552246\n",
      "tensor(3.2781, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 511, loss 3.2781314849853516\n",
      "tensor(3.2780, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 512, loss 3.2780025005340576\n",
      "tensor(3.2779, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 513, loss 3.2778728008270264\n",
      "tensor(3.2777, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 514, loss 3.277742624282837\n",
      "tensor(3.2776, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 515, loss 3.277613401412964\n",
      "tensor(3.2775, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 516, loss 3.2774856090545654\n",
      "tensor(3.2774, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 517, loss 3.2773549556732178\n",
      "tensor(3.2772, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 518, loss 3.2772257328033447\n",
      "tensor(3.2771, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 519, loss 3.2770955562591553\n",
      "tensor(3.2770, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 520, loss 3.2769668102264404\n",
      "tensor(3.2768, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 521, loss 3.276838541030884\n",
      "tensor(3.2767, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 522, loss 3.2767081260681152\n",
      "tensor(3.2766, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 523, loss 3.276577949523926\n",
      "tensor(3.2765, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 524, loss 3.2764501571655273\n",
      "tensor(3.2763, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 525, loss 3.2763192653656006\n",
      "tensor(3.2762, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 526, loss 3.276191473007202\n",
      "tensor(3.2761, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 527, loss 3.27606201171875\n",
      "tensor(3.2759, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 528, loss 3.2759320735931396\n",
      "tensor(3.2758, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 529, loss 3.2758030891418457\n",
      "tensor(3.2757, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 530, loss 3.275672674179077\n",
      "tensor(3.2755, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 531, loss 3.2755446434020996\n",
      "tensor(3.2754, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 532, loss 3.275414228439331\n",
      "tensor(3.2753, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 533, loss 3.275285243988037\n",
      "tensor(3.2752, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 534, loss 3.275156259536743\n",
      "tensor(3.2750, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 535, loss 3.275026559829712\n",
      "tensor(3.2749, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 536, loss 3.2748992443084717\n",
      "tensor(3.2748, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 537, loss 3.2747690677642822\n",
      "tensor(3.2746, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 538, loss 3.274639844894409\n",
      "tensor(3.2745, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 539, loss 3.2745110988616943\n",
      "tensor(3.2744, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 540, loss 3.2743821144104004\n",
      "tensor(3.2743, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 541, loss 3.2742528915405273\n",
      "tensor(3.2741, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 542, loss 3.2741246223449707\n",
      "tensor(3.2740, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 543, loss 3.273993492126465\n",
      "tensor(3.2739, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 544, loss 3.273865222930908\n",
      "tensor(3.2737, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 545, loss 3.2737362384796143\n",
      "tensor(3.2736, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 546, loss 3.273606777191162\n",
      "tensor(3.2735, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 547, loss 3.273477792739868\n",
      "tensor(3.2734, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 548, loss 3.273350477218628\n",
      "tensor(3.2732, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 549, loss 3.273219585418701\n",
      "tensor(3.2731, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 550, loss 3.2730910778045654\n",
      "tensor(3.2730, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 551, loss 3.2729620933532715\n",
      "tensor(3.2728, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 552, loss 3.2728331089019775\n",
      "tensor(3.2727, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 553, loss 3.2727043628692627\n",
      "tensor(3.2726, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 554, loss 3.272575855255127\n",
      "tensor(3.2724, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 555, loss 3.2724461555480957\n",
      "tensor(3.2723, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 556, loss 3.272317886352539\n",
      "tensor(3.2722, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 557, loss 3.272188186645508\n",
      "tensor(3.2721, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 558, loss 3.2720601558685303\n",
      "tensor(3.2719, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 559, loss 3.2719309329986572\n",
      "tensor(3.2718, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 560, loss 3.2718024253845215\n",
      "tensor(3.2717, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 561, loss 3.2716729640960693\n",
      "tensor(3.2715, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 562, loss 3.2715444564819336\n",
      "tensor(3.2714, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 563, loss 3.271416187286377\n",
      "tensor(3.2713, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 564, loss 3.2712864875793457\n",
      "tensor(3.2712, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 565, loss 3.2711589336395264\n",
      "tensor(3.2710, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 566, loss 3.271029472351074\n",
      "tensor(3.2709, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 567, loss 3.270900249481201\n",
      "tensor(3.2708, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 568, loss 3.2707724571228027\n",
      "tensor(3.2706, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 569, loss 3.270643472671509\n",
      "tensor(3.2705, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 570, loss 3.2705140113830566\n",
      "tensor(3.2704, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 571, loss 3.2703850269317627\n",
      "tensor(3.2703, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 572, loss 3.2702581882476807\n",
      "tensor(3.2701, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 573, loss 3.2701282501220703\n",
      "tensor(3.2700, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 574, loss 3.2699999809265137\n",
      "tensor(3.2699, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 575, loss 3.269871473312378\n",
      "tensor(3.2697, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 576, loss 3.2697434425354004\n",
      "tensor(3.2696, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 577, loss 3.269613027572632\n",
      "tensor(3.2695, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 578, loss 3.2694852352142334\n",
      "tensor(3.2694, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 579, loss 3.269357681274414\n",
      "tensor(3.2692, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 580, loss 3.26922869682312\n",
      "tensor(3.2691, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 581, loss 3.2690999507904053\n",
      "tensor(3.2690, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 582, loss 3.268972635269165\n",
      "tensor(3.2688, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 583, loss 3.268842935562134\n",
      "tensor(3.2687, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 584, loss 3.268714666366577\n",
      "tensor(3.2686, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 585, loss 3.268585205078125\n",
      "tensor(3.2685, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 586, loss 3.268458127975464\n",
      "tensor(3.2683, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 587, loss 3.2683298587799072\n",
      "tensor(3.2682, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 588, loss 3.2682008743286133\n",
      "tensor(3.2681, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 589, loss 3.2680723667144775\n",
      "tensor(3.2679, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 590, loss 3.2679436206817627\n",
      "tensor(3.2678, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 591, loss 3.267815113067627\n",
      "tensor(3.2677, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 592, loss 3.2676868438720703\n",
      "tensor(3.2676, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 593, loss 3.2675578594207764\n",
      "tensor(3.2674, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 594, loss 3.267430067062378\n",
      "tensor(3.2673, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 595, loss 3.2673027515411377\n",
      "tensor(3.2672, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 596, loss 3.2671728134155273\n",
      "tensor(3.2670, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 597, loss 3.267045259475708\n",
      "tensor(3.2669, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 598, loss 3.2669169902801514\n",
      "tensor(3.2668, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 599, loss 3.266789197921753\n",
      "tensor(3.2667, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 600, loss 3.266660451889038\n",
      "tensor(3.2665, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 601, loss 3.266531229019165\n",
      "tensor(3.2664, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 602, loss 3.266404628753662\n",
      "tensor(3.2663, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 603, loss 3.2662761211395264\n",
      "tensor(3.2661, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 604, loss 3.2661478519439697\n",
      "tensor(3.2660, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 605, loss 3.266019344329834\n",
      "tensor(3.2659, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 606, loss 3.2658917903900146\n",
      "tensor(3.2658, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 607, loss 3.265761613845825\n",
      "tensor(3.2656, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 608, loss 3.2656338214874268\n",
      "tensor(3.2655, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 609, loss 3.265505790710449\n",
      "tensor(3.2654, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 610, loss 3.265377998352051\n",
      "tensor(3.2652, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 611, loss 3.265249013900757\n",
      "tensor(3.2651, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 612, loss 3.2651207447052\n",
      "tensor(3.2650, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 613, loss 3.264993906021118\n",
      "tensor(3.2649, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 614, loss 3.2648656368255615\n",
      "tensor(3.2647, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 615, loss 3.2647385597229004\n",
      "tensor(3.2646, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 616, loss 3.2646095752716064\n",
      "tensor(3.2645, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 617, loss 3.26448130607605\n",
      "tensor(3.2644, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 618, loss 3.2643542289733887\n",
      "tensor(3.2642, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 619, loss 3.2642247676849365\n",
      "tensor(3.2641, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 620, loss 3.2640981674194336\n",
      "tensor(3.2640, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 621, loss 3.2639691829681396\n",
      "tensor(3.2638, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 622, loss 3.263840436935425\n",
      "tensor(3.2637, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 623, loss 3.2637126445770264\n",
      "tensor(3.2636, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 624, loss 3.263584852218628\n",
      "tensor(3.2635, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 625, loss 3.263458251953125\n",
      "tensor(3.2633, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 626, loss 3.2633304595947266\n",
      "tensor(3.2632, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 627, loss 3.2632017135620117\n",
      "tensor(3.2631, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 628, loss 3.263073682785034\n",
      "tensor(3.2629, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 629, loss 3.262946128845215\n",
      "tensor(3.2628, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 630, loss 3.2628188133239746\n",
      "tensor(3.2627, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 631, loss 3.262690305709839\n",
      "tensor(3.2626, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 632, loss 3.2625620365142822\n",
      "tensor(3.2624, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 633, loss 3.2624337673187256\n",
      "tensor(3.2623, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 634, loss 3.2623066902160645\n",
      "tensor(3.2622, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 635, loss 3.262178421020508\n",
      "tensor(3.2621, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 636, loss 3.262050151824951\n",
      "tensor(3.2619, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 637, loss 3.2619223594665527\n",
      "tensor(3.2618, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 638, loss 3.261796474456787\n",
      "tensor(3.2617, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 639, loss 3.2616689205169678\n",
      "tensor(3.2615, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 640, loss 3.261540412902832\n",
      "tensor(3.2614, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 641, loss 3.2614128589630127\n",
      "tensor(3.2613, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 642, loss 3.261284351348877\n",
      "tensor(3.2612, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 643, loss 3.261157512664795\n",
      "tensor(3.2610, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 644, loss 3.2610292434692383\n",
      "tensor(3.2609, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 645, loss 3.260902166366577\n",
      "tensor(3.2608, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 646, loss 3.2607738971710205\n",
      "tensor(3.2606, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 647, loss 3.2606465816497803\n",
      "tensor(3.2605, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 648, loss 3.26051926612854\n",
      "tensor(3.2604, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 649, loss 3.2603912353515625\n",
      "tensor(3.2603, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 650, loss 3.2602627277374268\n",
      "tensor(3.2601, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 651, loss 3.260136365890503\n",
      "tensor(3.2600, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 652, loss 3.2600083351135254\n",
      "tensor(3.2599, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 653, loss 3.259880542755127\n",
      "tensor(3.2598, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 654, loss 3.2597525119781494\n",
      "tensor(3.2596, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 655, loss 3.2596242427825928\n",
      "tensor(3.2595, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 656, loss 3.259498357772827\n",
      "tensor(3.2594, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 657, loss 3.259371757507324\n",
      "tensor(3.2592, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 658, loss 3.259243965148926\n",
      "tensor(3.2591, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 659, loss 3.2591164112091064\n",
      "tensor(3.2590, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 660, loss 3.258988618850708\n",
      "tensor(3.2589, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 661, loss 3.2588603496551514\n",
      "tensor(3.2587, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 662, loss 3.2587339878082275\n",
      "tensor(3.2586, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 663, loss 3.258606433868408\n",
      "tensor(3.2585, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 664, loss 3.2584776878356934\n",
      "tensor(3.2584, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 665, loss 3.2583510875701904\n",
      "tensor(3.2582, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 666, loss 3.2582242488861084\n",
      "tensor(3.2581, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 667, loss 3.2580959796905518\n",
      "tensor(3.2580, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 668, loss 3.2579703330993652\n",
      "tensor(3.2578, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 669, loss 3.2578413486480713\n",
      "tensor(3.2577, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 670, loss 3.2577145099639893\n",
      "tensor(3.2576, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 671, loss 3.25758695602417\n",
      "tensor(3.2575, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 672, loss 3.257460117340088\n",
      "tensor(3.2573, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 673, loss 3.2573330402374268\n",
      "tensor(3.2572, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 674, loss 3.2572062015533447\n",
      "tensor(3.2571, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 675, loss 3.257077217102051\n",
      "tensor(3.2570, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 676, loss 3.256950855255127\n",
      "tensor(3.2568, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 677, loss 3.2568228244781494\n",
      "tensor(3.2567, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 678, loss 3.2566964626312256\n",
      "tensor(3.2566, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 679, loss 3.2565693855285645\n",
      "tensor(3.2564, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 680, loss 3.256442070007324\n",
      "tensor(3.2563, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 681, loss 3.256314277648926\n",
      "tensor(3.2562, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 682, loss 3.256187915802002\n",
      "tensor(3.2561, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 683, loss 3.256059169769287\n",
      "tensor(3.2559, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 684, loss 3.2559332847595215\n",
      "tensor(3.2558, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 685, loss 3.2558059692382812\n",
      "tensor(3.2557, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 686, loss 3.25567889213562\n",
      "tensor(3.2556, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 687, loss 3.255551338195801\n",
      "tensor(3.2554, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 688, loss 3.2554244995117188\n",
      "tensor(3.2553, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 689, loss 3.2552969455718994\n",
      "tensor(3.2552, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 690, loss 3.2551705837249756\n",
      "tensor(3.2550, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 691, loss 3.2550430297851562\n",
      "tensor(3.2549, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 692, loss 3.2549169063568115\n",
      "tensor(3.2548, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 693, loss 3.2547895908355713\n",
      "tensor(3.2547, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 694, loss 3.254662036895752\n",
      "tensor(3.2545, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 695, loss 3.254535436630249\n",
      "tensor(3.2544, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 696, loss 3.254408359527588\n",
      "tensor(3.2543, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 697, loss 3.2542808055877686\n",
      "tensor(3.2542, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 698, loss 3.2541556358337402\n",
      "tensor(3.2540, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 699, loss 3.254028081893921\n",
      "tensor(3.2539, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 700, loss 3.2539005279541016\n",
      "tensor(3.2538, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 701, loss 3.2537736892700195\n",
      "tensor(3.2536, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 702, loss 3.2536468505859375\n",
      "tensor(3.2535, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 703, loss 3.2535197734832764\n",
      "tensor(3.2534, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 704, loss 3.2533934116363525\n",
      "tensor(3.2533, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 705, loss 3.2532668113708496\n",
      "tensor(3.2531, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 706, loss 3.253140449523926\n",
      "tensor(3.2530, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 707, loss 3.2530126571655273\n",
      "tensor(3.2529, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 708, loss 3.252885341644287\n",
      "tensor(3.2528, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 709, loss 3.252758741378784\n",
      "tensor(3.2526, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 710, loss 3.2526328563690186\n",
      "tensor(3.2525, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 711, loss 3.252505302429199\n",
      "tensor(3.2524, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 712, loss 3.2523794174194336\n",
      "tensor(3.2523, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 713, loss 3.2522521018981934\n",
      "tensor(3.2521, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 714, loss 3.2521250247955322\n",
      "tensor(3.2520, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 715, loss 3.251997947692871\n",
      "tensor(3.2519, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 716, loss 3.2518725395202637\n",
      "tensor(3.2517, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 717, loss 3.25174617767334\n",
      "tensor(3.2516, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 718, loss 3.2516186237335205\n",
      "tensor(3.2515, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 719, loss 3.251492500305176\n",
      "tensor(3.2514, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 720, loss 3.251366138458252\n",
      "tensor(3.2512, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 721, loss 3.251239538192749\n",
      "tensor(3.2511, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 722, loss 3.251112461090088\n",
      "tensor(3.2510, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 723, loss 3.250986099243164\n",
      "tensor(3.2509, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 724, loss 3.2508580684661865\n",
      "tensor(3.2507, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 725, loss 3.2507331371307373\n",
      "tensor(3.2506, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 726, loss 3.2506046295166016\n",
      "tensor(3.2505, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 727, loss 3.2504796981811523\n",
      "tensor(3.2504, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 728, loss 3.250351667404175\n",
      "tensor(3.2502, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 729, loss 3.2502260208129883\n",
      "tensor(3.2501, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 730, loss 3.250098466873169\n",
      "tensor(3.2500, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 731, loss 3.2499735355377197\n",
      "tensor(3.2498, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 732, loss 3.2498466968536377\n",
      "tensor(3.2497, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 733, loss 3.2497196197509766\n",
      "tensor(3.2496, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 734, loss 3.2495932579040527\n",
      "tensor(3.2495, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 735, loss 3.249467372894287\n",
      "tensor(3.2493, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 736, loss 3.249340772628784\n",
      "tensor(3.2492, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 737, loss 3.2492148876190186\n",
      "tensor(3.2491, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 738, loss 3.24908709526062\n",
      "tensor(3.2490, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 739, loss 3.248962163925171\n",
      "tensor(3.2488, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 740, loss 3.248836040496826\n",
      "tensor(3.2487, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 741, loss 3.2487096786499023\n",
      "tensor(3.2486, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 742, loss 3.248582363128662\n",
      "tensor(3.2485, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 743, loss 3.248455286026001\n",
      "tensor(3.2483, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 744, loss 3.2483303546905518\n",
      "tensor(3.2482, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 745, loss 3.2482035160064697\n",
      "tensor(3.2481, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 746, loss 3.2480764389038086\n",
      "tensor(3.2480, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 747, loss 3.247951030731201\n",
      "tensor(3.2478, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 748, loss 3.2478246688842773\n",
      "tensor(3.2477, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 749, loss 3.2476980686187744\n",
      "tensor(3.2476, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 750, loss 3.247573137283325\n",
      "tensor(3.2474, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 751, loss 3.247446060180664\n",
      "tensor(3.2473, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 752, loss 3.247321128845215\n",
      "tensor(3.2472, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 753, loss 3.2471938133239746\n",
      "tensor(3.2471, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 754, loss 3.247067451477051\n",
      "tensor(3.2469, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 755, loss 3.2469418048858643\n",
      "tensor(3.2468, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 756, loss 3.2468156814575195\n",
      "tensor(3.2467, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 757, loss 3.2466881275177\n",
      "tensor(3.2466, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 758, loss 3.2465624809265137\n",
      "tensor(3.2464, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 759, loss 3.24643611907959\n",
      "tensor(3.2463, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 760, loss 3.246310234069824\n",
      "tensor(3.2462, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 761, loss 3.2461845874786377\n",
      "tensor(3.2461, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 762, loss 3.2460577487945557\n",
      "tensor(3.2459, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 763, loss 3.2459325790405273\n",
      "tensor(3.2458, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 764, loss 3.2458059787750244\n",
      "tensor(3.2457, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 765, loss 3.2456796169281006\n",
      "tensor(3.2456, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 766, loss 3.2455546855926514\n",
      "tensor(3.2454, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 767, loss 3.245429039001465\n",
      "tensor(3.2453, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 768, loss 3.24530291557312\n",
      "tensor(3.2452, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 769, loss 3.245176076889038\n",
      "tensor(3.2450, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 770, loss 3.2450497150421143\n",
      "tensor(3.2449, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 771, loss 3.2449240684509277\n",
      "tensor(3.2448, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 772, loss 3.2447988986968994\n",
      "tensor(3.2447, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 773, loss 3.2446718215942383\n",
      "tensor(3.2445, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 774, loss 3.2445454597473145\n",
      "tensor(3.2444, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 775, loss 3.2444205284118652\n",
      "tensor(3.2443, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 776, loss 3.244295120239258\n",
      "tensor(3.2442, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 777, loss 3.244168758392334\n",
      "tensor(3.2440, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 778, loss 3.244041919708252\n",
      "tensor(3.2439, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 779, loss 3.2439162731170654\n",
      "tensor(3.2438, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 780, loss 3.243790864944458\n",
      "tensor(3.2437, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 781, loss 3.2436654567718506\n",
      "tensor(3.2435, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 782, loss 3.243539810180664\n",
      "tensor(3.2434, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 783, loss 3.2434141635894775\n",
      "tensor(3.2433, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 784, loss 3.243288278579712\n",
      "tensor(3.2432, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 785, loss 3.243161678314209\n",
      "tensor(3.2430, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 786, loss 3.2430362701416016\n",
      "tensor(3.2429, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 787, loss 3.242910861968994\n",
      "tensor(3.2428, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 788, loss 3.2427854537963867\n",
      "tensor(3.2427, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 789, loss 3.2426583766937256\n",
      "tensor(3.2425, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 790, loss 3.2425336837768555\n",
      "tensor(3.2424, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 791, loss 3.242408514022827\n",
      "tensor(3.2423, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 792, loss 3.242281913757324\n",
      "tensor(3.2422, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 793, loss 3.242157459259033\n",
      "tensor(3.2420, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 794, loss 3.2420318126678467\n",
      "tensor(3.2419, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 795, loss 3.241905927658081\n",
      "tensor(3.2418, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 796, loss 3.241779088973999\n",
      "tensor(3.2417, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 797, loss 3.24165415763855\n",
      "tensor(3.2415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 798, loss 3.241528272628784\n",
      "tensor(3.2414, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 799, loss 3.2414028644561768\n",
      "tensor(3.2413, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 800, loss 3.2412779331207275\n",
      "tensor(3.2412, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 801, loss 3.24115252494812\n",
      "tensor(3.2410, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 802, loss 3.241025686264038\n",
      "tensor(3.2409, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 803, loss 3.2409002780914307\n",
      "tensor(3.2408, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 804, loss 3.240774393081665\n",
      "tensor(3.2406, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 805, loss 3.2406489849090576\n",
      "tensor(3.2405, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 806, loss 3.2405247688293457\n",
      "tensor(3.2404, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 807, loss 3.2403993606567383\n",
      "tensor(3.2403, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 808, loss 3.240273952484131\n",
      "tensor(3.2401, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 809, loss 3.240147352218628\n",
      "tensor(3.2400, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 810, loss 3.2400221824645996\n",
      "tensor(3.2399, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 811, loss 3.2398972511291504\n",
      "tensor(3.2398, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 812, loss 3.2397708892822266\n",
      "tensor(3.2396, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 813, loss 3.2396466732025146\n",
      "tensor(3.2395, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 814, loss 3.2395212650299072\n",
      "tensor(3.2394, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 815, loss 3.2393958568573\n",
      "tensor(3.2393, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 816, loss 3.239269495010376\n",
      "tensor(3.2391, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 817, loss 3.2391440868377686\n",
      "tensor(3.2390, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 818, loss 3.2390196323394775\n",
      "tensor(3.2389, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 819, loss 3.238893747329712\n",
      "tensor(3.2388, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 820, loss 3.2387685775756836\n",
      "tensor(3.2386, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 821, loss 3.2386443614959717\n",
      "tensor(3.2385, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 822, loss 3.2385196685791016\n",
      "tensor(3.2384, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 823, loss 3.2383933067321777\n",
      "tensor(3.2383, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 824, loss 3.238266706466675\n",
      "tensor(3.2381, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 825, loss 3.238142490386963\n",
      "tensor(3.2380, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 826, loss 3.238018274307251\n",
      "tensor(3.2379, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 827, loss 3.237891912460327\n",
      "tensor(3.2378, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 828, loss 3.2377660274505615\n",
      "tensor(3.2376, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 829, loss 3.2376410961151123\n",
      "tensor(3.2375, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 830, loss 3.2375175952911377\n",
      "tensor(3.2374, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 831, loss 3.237391233444214\n",
      "tensor(3.2373, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 832, loss 3.2372663021087646\n",
      "tensor(3.2371, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 833, loss 3.2371413707733154\n",
      "tensor(3.2370, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 834, loss 3.237016201019287\n",
      "tensor(3.2369, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 835, loss 3.236891031265259\n",
      "tensor(3.2368, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 836, loss 3.2367656230926514\n",
      "tensor(3.2366, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 837, loss 3.236639976501465\n",
      "tensor(3.2365, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 838, loss 3.236515998840332\n",
      "tensor(3.2364, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 839, loss 3.236391067504883\n",
      "tensor(3.2363, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 840, loss 3.236264705657959\n",
      "tensor(3.2361, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 841, loss 3.2361414432525635\n",
      "tensor(3.2360, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 842, loss 3.2360165119171143\n",
      "tensor(3.2359, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 843, loss 3.2358908653259277\n",
      "tensor(3.2358, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 844, loss 3.2357656955718994\n",
      "tensor(3.2356, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 845, loss 3.235640525817871\n",
      "tensor(3.2355, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 846, loss 3.235515832901001\n",
      "tensor(3.2354, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 847, loss 3.2353909015655518\n",
      "tensor(3.2353, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 848, loss 3.2352659702301025\n",
      "tensor(3.2351, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 849, loss 3.235140800476074\n",
      "tensor(3.2350, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 850, loss 3.2350149154663086\n",
      "tensor(3.2349, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 851, loss 3.234890937805176\n",
      "tensor(3.2348, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 852, loss 3.234766721725464\n",
      "tensor(3.2346, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 853, loss 3.2346413135528564\n",
      "tensor(3.2345, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 854, loss 3.2345170974731445\n",
      "tensor(3.2344, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 855, loss 3.2343907356262207\n",
      "tensor(3.2343, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 856, loss 3.234266757965088\n",
      "tensor(3.2341, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 857, loss 3.234142541885376\n",
      "tensor(3.2340, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 858, loss 3.2340171337127686\n",
      "tensor(3.2339, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 859, loss 3.2338929176330566\n",
      "tensor(3.2338, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 860, loss 3.23376727104187\n",
      "tensor(3.2336, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 861, loss 3.233643054962158\n",
      "tensor(3.2335, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 862, loss 3.233518362045288\n",
      "tensor(3.2334, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 863, loss 3.233393430709839\n",
      "tensor(3.2333, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 864, loss 3.2332684993743896\n",
      "tensor(3.2331, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 865, loss 3.2331435680389404\n",
      "tensor(3.2330, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 866, loss 3.2330198287963867\n",
      "tensor(3.2329, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 867, loss 3.2328948974609375\n",
      "tensor(3.2328, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 868, loss 3.2327706813812256\n",
      "tensor(3.2326, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 869, loss 3.2326464653015137\n",
      "tensor(3.2325, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 870, loss 3.2325215339660645\n",
      "tensor(3.2324, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 871, loss 3.2323973178863525\n",
      "tensor(3.2323, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 872, loss 3.232272148132324\n",
      "tensor(3.2321, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 873, loss 3.232147216796875\n",
      "tensor(3.2320, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 874, loss 3.232022285461426\n",
      "tensor(3.2319, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 875, loss 3.2318975925445557\n",
      "tensor(3.2318, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 876, loss 3.231773853302002\n",
      "tensor(3.2316, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 877, loss 3.231649160385132\n",
      "tensor(3.2315, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 878, loss 3.2315235137939453\n",
      "tensor(3.2314, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 879, loss 3.2313995361328125\n",
      "tensor(3.2313, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 880, loss 3.2312746047973633\n",
      "tensor(3.2312, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 881, loss 3.2311503887176514\n",
      "tensor(3.2310, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 882, loss 3.231027603149414\n",
      "tensor(3.2309, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 883, loss 3.2309014797210693\n",
      "tensor(3.2308, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 884, loss 3.2307775020599365\n",
      "tensor(3.2307, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 885, loss 3.2306525707244873\n",
      "tensor(3.2305, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 886, loss 3.2305283546447754\n",
      "tensor(3.2304, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 887, loss 3.230403423309326\n",
      "tensor(3.2303, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 888, loss 3.2302794456481934\n",
      "tensor(3.2302, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 889, loss 3.2301552295684814\n",
      "tensor(3.2300, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 890, loss 3.2300310134887695\n",
      "tensor(3.2299, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 891, loss 3.2299063205718994\n",
      "tensor(3.2298, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 892, loss 3.2297821044921875\n",
      "tensor(3.2297, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 893, loss 3.229658365249634\n",
      "tensor(3.2295, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 894, loss 3.229534387588501\n",
      "tensor(3.2294, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 895, loss 3.229409694671631\n",
      "tensor(3.2293, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 896, loss 3.22928524017334\n",
      "tensor(3.2292, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 897, loss 3.229161262512207\n",
      "tensor(3.2290, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 898, loss 3.229037284851074\n",
      "tensor(3.2289, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 899, loss 3.228912353515625\n",
      "tensor(3.2288, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 900, loss 3.2287888526916504\n",
      "tensor(3.2287, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 901, loss 3.2286646366119385\n",
      "tensor(3.2285, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 902, loss 3.228541135787964\n",
      "tensor(3.2284, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 903, loss 3.2284162044525146\n",
      "tensor(3.2283, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 904, loss 3.2282919883728027\n",
      "tensor(3.2282, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 905, loss 3.228168249130249\n",
      "tensor(3.2280, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 906, loss 3.228044033050537\n",
      "tensor(3.2279, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 907, loss 3.227919816970825\n",
      "tensor(3.2278, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 908, loss 3.2277956008911133\n",
      "tensor(3.2277, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 909, loss 3.2276713848114014\n",
      "tensor(3.2275, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 910, loss 3.2275466918945312\n",
      "tensor(3.2274, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 911, loss 3.227423667907715\n",
      "tensor(3.2273, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 912, loss 3.2272984981536865\n",
      "tensor(3.2272, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 913, loss 3.227174997329712\n",
      "tensor(3.2270, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 914, loss 3.2270493507385254\n",
      "tensor(3.2269, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 915, loss 3.2269270420074463\n",
      "tensor(3.2268, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 916, loss 3.2268025875091553\n",
      "tensor(3.2267, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 917, loss 3.226677417755127\n",
      "tensor(3.2266, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 918, loss 3.2265539169311523\n",
      "tensor(3.2264, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 919, loss 3.2264297008514404\n",
      "tensor(3.2263, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 920, loss 3.226306438446045\n",
      "tensor(3.2262, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 921, loss 3.226181745529175\n",
      "tensor(3.2261, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 922, loss 3.226057529449463\n",
      "tensor(3.2259, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 923, loss 3.2259345054626465\n",
      "tensor(3.2258, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 924, loss 3.2258100509643555\n",
      "tensor(3.2257, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 925, loss 3.2256858348846436\n",
      "tensor(3.2256, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 926, loss 3.22556209564209\n",
      "tensor(3.2254, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 927, loss 3.2254393100738525\n",
      "tensor(3.2253, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 928, loss 3.2253153324127197\n",
      "tensor(3.2252, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 929, loss 3.225191354751587\n",
      "tensor(3.2251, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 930, loss 3.2250678539276123\n",
      "tensor(3.2249, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 931, loss 3.2249441146850586\n",
      "tensor(3.2248, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 932, loss 3.2248198986053467\n",
      "tensor(3.2247, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 933, loss 3.224695920944214\n",
      "tensor(3.2246, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 934, loss 3.2245731353759766\n",
      "tensor(3.2244, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 935, loss 3.224447727203369\n",
      "tensor(3.2243, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 936, loss 3.2243247032165527\n",
      "tensor(3.2242, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 937, loss 3.2242019176483154\n",
      "tensor(3.2241, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 938, loss 3.22407603263855\n",
      "tensor(3.2240, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 939, loss 3.223954677581787\n",
      "tensor(3.2238, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 940, loss 3.223830461502075\n",
      "tensor(3.2237, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 941, loss 3.223707675933838\n",
      "tensor(3.2236, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 942, loss 3.223583459854126\n",
      "tensor(3.2235, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 943, loss 3.223459243774414\n",
      "tensor(3.2233, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 944, loss 3.2233364582061768\n",
      "tensor(3.2232, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 945, loss 3.2232108116149902\n",
      "tensor(3.2231, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 946, loss 3.223088026046753\n",
      "tensor(3.2230, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 947, loss 3.222964286804199\n",
      "tensor(3.2228, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 948, loss 3.2228400707244873\n",
      "tensor(3.2227, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 949, loss 3.222717046737671\n",
      "tensor(3.2226, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 950, loss 3.2225937843322754\n",
      "tensor(3.2225, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 951, loss 3.2224700450897217\n",
      "tensor(3.2223, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 952, loss 3.222346305847168\n",
      "tensor(3.2222, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 953, loss 3.2222232818603516\n",
      "tensor(3.2221, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 954, loss 3.2220985889434814\n",
      "tensor(3.2220, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 955, loss 3.2219769954681396\n",
      "tensor(3.2219, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 956, loss 3.221853017807007\n",
      "tensor(3.2217, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 957, loss 3.2217307090759277\n",
      "tensor(3.2216, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 958, loss 3.2216055393218994\n",
      "tensor(3.2215, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 959, loss 3.2214813232421875\n",
      "tensor(3.2214, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 960, loss 3.221359968185425\n",
      "tensor(3.2212, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 961, loss 3.2212350368499756\n",
      "tensor(3.2211, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 962, loss 3.221112012863159\n",
      "tensor(3.2210, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 963, loss 3.2209889888763428\n",
      "tensor(3.2209, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 964, loss 3.2208645343780518\n",
      "tensor(3.2207, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 965, loss 3.2207417488098145\n",
      "tensor(3.2206, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 966, loss 3.220618963241577\n",
      "tensor(3.2205, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 967, loss 3.2204949855804443\n",
      "tensor(3.2204, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 968, loss 3.220371961593628\n",
      "tensor(3.2202, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 969, loss 3.220247507095337\n",
      "tensor(3.2201, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 970, loss 3.220125913619995\n",
      "tensor(3.2200, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 971, loss 3.2200019359588623\n",
      "tensor(3.2199, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 972, loss 3.2198774814605713\n",
      "tensor(3.2198, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 973, loss 3.219754934310913\n",
      "tensor(3.2196, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 974, loss 3.2196319103240967\n",
      "tensor(3.2195, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 975, loss 3.219508171081543\n",
      "tensor(3.2194, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 976, loss 3.2193851470947266\n",
      "tensor(3.2193, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 977, loss 3.2192630767822266\n",
      "tensor(3.2191, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 978, loss 3.2191383838653564\n",
      "tensor(3.2190, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 979, loss 3.2190163135528564\n",
      "tensor(3.2189, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 980, loss 3.2188925743103027\n",
      "tensor(3.2188, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 981, loss 3.218768835067749\n",
      "tensor(3.2186, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 982, loss 3.2186453342437744\n",
      "tensor(3.2185, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 983, loss 3.2185239791870117\n",
      "tensor(3.2184, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 984, loss 3.2183997631073\n",
      "tensor(3.2183, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 985, loss 3.2182774543762207\n",
      "tensor(3.2182, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 986, loss 3.218153476715088\n",
      "tensor(3.2180, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 987, loss 3.218031883239746\n",
      "tensor(3.2179, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 988, loss 3.2179086208343506\n",
      "tensor(3.2178, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 989, loss 3.2177844047546387\n",
      "tensor(3.2177, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 990, loss 3.217660903930664\n",
      "tensor(3.2175, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 991, loss 3.2175395488739014\n",
      "tensor(3.2174, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 992, loss 3.2174160480499268\n",
      "tensor(3.2173, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 993, loss 3.2172927856445312\n",
      "tensor(3.2172, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 994, loss 3.2171690464019775\n",
      "tensor(3.2170, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 995, loss 3.217047691345215\n",
      "tensor(3.2169, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 996, loss 3.2169244289398193\n",
      "tensor(3.2168, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 997, loss 3.2168002128601074\n",
      "tensor(3.2167, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 998, loss 3.216676950454712\n",
      "tensor(3.2166, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "epoch 999, loss 3.216554641723633\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    inputs = Variable(torch.from_numpy(x_train).cuda())\n",
    "    labels=Variable(torch.from_numpy(y_train).cuda())\n",
    "    optimizer.zero_grad()\n",
    "    outputs=model(inputs)\n",
    "    loss=criterion(outputs,labels)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(\"epoch {}, loss {}\".format(epoch,loss.item()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5913738]\n",
      " [ 1.532154 ]\n",
      " [ 3.6556816]\n",
      " [ 5.7792096]\n",
      " [ 7.902737 ]\n",
      " [10.026265 ]\n",
      " [12.149793 ]\n",
      " [14.27332  ]\n",
      " [16.396849 ]\n",
      " [18.520376 ]\n",
      " [20.643904 ]\n",
      " [22.767431 ]\n",
      " [24.890959 ]\n",
      " [27.014486 ]\n",
      " [29.138016 ]\n",
      " [31.261543 ]\n",
      " [33.38507  ]\n",
      " [35.5086   ]\n",
      " [37.632126 ]\n",
      " [39.755653 ]\n",
      " [41.87918  ]]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    predicted=model(Variable(torch.from_numpy(x_train).cuda())).cpu().data.numpy()\n",
    "    print(predicted)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAo7klEQVR4nO3deXSc1Znn8e+VLKm0qyTL2mUJY1ve5E2AjR1wAqZJIBAcCElDt1lO0+k0dHfSDpDpkx5OuqebZEgyYQ6dOcyEARKasLQJdCYbBkwC2AQb5AVbeJVl2bL2XSqpVLrzh0pCElpKUq3S73OOjqre9616H79Venzr1r3PNdZaREQk8kSFOgAREZkeJXARkQilBC4iEqGUwEVEIpQSuIhIhJoXzJPNnz/fFhUVBfOUIiIRb//+/Q3W2szR24OawIuKiti3b18wTykiEvGMMWfG2q4uFBGRCKUELiISoZTARUQiVFD7wMfidruprq7G5XKFOpRZzeFwkJ+fT0xMTKhDERE/CXkCr66uJjk5maKiIowxoQ5nVrLW0tjYSHV1NcXFxaEOR0T8JORdKC6Xi4yMDCXvADLGkJGRoU85IrNMyBM4oOQdBLrGIrNPWCRwEZHZqrvXQ2dPX0Cee84n8MbGRtasWcOaNWvIzs4mLy9v6H5vb69fzrFlyxaWLl1KaWkpJSUl3HvvvbS0tEz6uH/5l3/xy/lFJPistRyrbefpPZW8VlEXkHNEXAI/eOEgD+1+iLtevouHdj/EwQsHZ/R8GRkZlJeXU15ezle/+lW+/vWvD92PjY2lr88//3M+88wzHDx4kIMHDxIXF8eNN9446WOUwEUiU0dPH/95sIb/d7CGZEcMGy/KCMh5IiqBH7xwkEf2PEJzdzP5Kfk0dzfzyJ5HZpzER7vjjjv4xje+wac//WkeeOABHnroIR555JGh/StXrqSyshKAn/3sZ1x66aWsWbOGv/zLv8Tj8Uz43LGxsXzve9+jqqqKAwcOAPCFL3yB9evXs2LFCh5//HEAHnzwQbq7u1mzZg233XbbuMeJSHjp6fPws71nONPQyRVL5vPlSwrITI4LyLkiKoHvrNiJ0+HEGe8kykThjHfidDjZWbHT7+c6duwYu3bt4vvf//64xxw9epTnnnuOt99+m/LycqKjo3nmmWcmfe7o6GhWr15NRUUFAE888QT79+9n3759PProozQ2NvLwww8THx9PeXn50HOOdZyIhIfu3oHGW9y8aD61eD63b1jI+oXpREUFbgBByMeBT0VVaxX5KfkjtqU6UqlqrfL7uW655Raio6MnPOa1115j//79XHLJJQB0d3ezYMECn55/+Fqkjz76KC+99BIAZ8+e5fjx42RkfPIjl6/HiUjw9PdbyqtbeOdEA59fncvCjERW5KYG5dwRlcALUwtp7m7GGe8c2tbqaqUwtdDv50pMTBy6PW/ePPr7+4fuD46nttayfft2/vVf/3VKz+3xeDh06BDLli1j9+7d7Nq1iz179pCQkMCWLVvGHK/t63EiEjyNHT28eqSWmlYXF2Umkp4YG9Tz+9yFYoyJNsZ8YIz5pfd+ujHmVWPMce9v52TPMVPbSrbR7GqmubuZfttPc3czza5mtpVsC+h5i4qKeP/99wF4//33OX36NABXXXUVL774InV1A98wNzU1cebMmFUfh7jdbr71rW9RUFBAaWkpra2tOJ1OEhISqKioYO/evUPHxsTE4Ha7ASY8TkSCb/+ZZp55t4qWbjefXZXNDatzSXYEt1TFVPrA/xY4Ouz+g8Br1trFwGve+wFVml3Kjo07cMY7qW6rxhnvZMfGHZRmlwb0vF/84hdpampizZo1/PjHP2bJkiUALF++nH/+53/mmmuuobS0lK1bt1JTUzPmc9x2222UlpaycuVKOjs7efnllwG49tpr6evro7S0lG9/+9ts2LBh6DH33HMPpaWl3HbbbRMeJyLBFxNtuHhBEn++cSEl2SnjTpbz98i54czwvthxDzImH3gK+G/AN6y11xtjPgK2WGtrjDE5wG5r7dKJnqesrMyOXtDh6NGjLFu2bNr/APGdrrXI9Lk9/ew91Uh6YiwrclOx1k46w3lw5JzT4STVkUqrq5VmV/OUG57GmP3W2rLR233tA/8fwP1A8rBtWdbaGgBvEh/z2ztjzD3APQCFhf7vqxYRmczBCwfZWbGTqtYqClML2VaybUoJ9GxTF7uO1tLS5Wb9woHeYl/KUwwfOQcM/d5ZsdMvPQeTdqEYY64H6qy1+6dzAmvt49baMmttWWbmJ5Z0ExEJqJnMH3G5Pbx2tJYX91djLdy8Pp8rlviex6paq0h1jByR4s+Rc760wDcBNxhjPgc4gBRjzM+AWmNMzrAulMDMFRURmYGZtIIvtLo4dK6V9QudbFyUQUz01KbOBHrk3KTRWGu/Za3Nt9YWAV8GXrfW3g68Amz3HrYdeNkvEYmI+NFUW8FdvX2cqGsHoGh+IndeXswVSzKnnLwh8CPnZjIT82FgqzHmOLDVe19EJKwUphbS6modsW2sVrC1lo8utPP0njP89sPaoZmVqQnTHxoY6JFzU5rIY63dDez23m4ErvJLFCIiAbKtZBuP7BmoZTR8JMjda+8eOqbd5eb1ijpO1XeSnepg6/Is4mMnnontq9Ls0oANdY6oWiiRYPfu3Vx//fUAvPLKKzz88PgfTFpaWvi3f/u3ofvnz5/n5ptvDniMInPJZK3gnj4Pz7xbxdmmLq5YksmtZQXMTwpM8Sl/i6ip9KHk8XgmrY0y2g033MANN9ww7v7BBP61r30NgNzcXF588cUZxSkinzRWK7irt4+E2HlDxafy0uJJSwjuVPiZUgscqKyspKSkhO3bt1NaWsrNN99MV1cXRUVFfOc732Hz5s288MIL/O53v2Pjxo2sW7eOW265hY6ODgB+85vfUFJSwubNm9m58+PKiE8++ST33nsvALW1tdx0002sXr2a1atX88477/Dggw9y8uRJ1qxZwze/+U0qKytZuXIlMFBv5c4772TVqlWsXbuWN954Y+g5t23bxrXXXsvixYu5//77gYH/YO644w5WrlzJqlWr+OEPfxjMSygSMfr7LfvPNPPEW6epbOgEYEVuasQlbwjDFvgL+85+YtuSrGRWF6Th9vTziw/OfWL/8twUVuSm0t3r4ZcHz4/Yd0tZgU/n/eijj/jJT37Cpk2buOuuu4a6NhwOB2+99RYNDQ1s27aNXbt2kZiYyHe/+11+8IMfcP/99/MXf/EXvP7661x88cXceuutYz7/3/zN33DllVfy0ksv4fF46Ojo4OGHH+bw4cOUl5cDDNUYB3jssccAOHToEBUVFVxzzTUcO3YMgPLycj744APi4uJYunQp9913H3V1dZw7d47Dhw8D+LTij8hc0+AtPnXBW3wqIynykvZwYZfAQ6WgoIBNmzYBcPvtt/Poo48CDCXkvXv3cuTIkaFjent72bhxIxUVFRQXF7N48eKhx4612MLrr7/O008/DQzUA09NTaW5uXnceN566y3uu+8+AEpKSli4cOFQAr/qqqtITR0YFrV8+XLOnDnDihUrOHXqFPfddx/XXXcd11xzzYyvichssq+yiXdONhI7L4rPrcphSVaST7MpZzqLM5DCLoFP1GKOiY6acH98bLTPLe7RRr+Qg/cHy8paa9m6dSvPPvvsiOPKy8sDsuL7RDVq4uI+/oIlOjqavr4+nE4nBw4c4Le//S2PPfYYzz//PE888YTf4xKJVHHzolmSlcSVSxb4PMJkeC2T4bM4g1FEzxfqA/eqqqpiz549ADz77LNs3rx5xP4NGzbw9ttvc+LECQC6uro4duwYJSUlnD59mpMnTw49dixXXXUVP/7xj4GB/uq2tjaSk5Npb28f8/grrrhiaCWeY8eOUVVVxdKl49cKa2hooL+/ny9+8Yv80z/901D5W5G5qrevnzeP1XP43MAY8JV5KVy7MmdKwwODuQrYdCiBey1btoynnnqK0tJSmpqa+Ku/+qsR+zMzM3nyySf5yle+QmlpKRs2bKCiogKHw8Hjjz/Oddddx+bNm1m4cOGYz/+jH/2IN954g1WrVrF+/Xo+/PBDMjIy2LRpEytXruSb3/zmiOO/9rWv4fF4WLVqFbfeeitPPvnkiJb3aOfOnWPLli2sWbOGO+64Y8qLTIjMJmebuvjZ3jO8f6aZ5q5ewLfiU6MFupbJTPlUTtZfwrWcbGVlJddff/3QF4CzVThca5FAcrk9/OF4A4fPtZKWEMPVy7IoSE+Y9vM9tPuhT9QyGbz/0JaH/BCxb8YrJ6sWuIjMGhdaXRw530ZZkZPbNyycUfKG0K0C5islcAaWTJvtrW+R2aqrt4/jtR8Xn7rj8iI+tXh6xadGC9UqYL4Ki1EovqxsITMTzK4ykWCw1lJxoZ03j9Xj6bfkOxOIj42eUfGpsQSylslMhTyBOxwOGhsbycjIUBIPEGstjY2NOByOUIcic5y/xlS3udy8frSO0w2d5Pi5+FQkCXkCz8/Pp7q6mvr6+lCHMqs5HA7y8/NDHYbMYf4aU93T5+GZvVV4+vu5cmkma/LTiIqam42/kCfwmJgYiouLQx2GiATYTNeH7OzpIzFuoPjUlUsyyUuL93t3SaTRl5giEhTTHVPd32/ZV9k0ovjU8tyUOZ+8IQxa4CIyN0xnfci6dhe7jtRR2+bi4gVJzE+OjDrdwaIWuIgExVTHVL9X2cSz756l3eXm+tIcri/NISlObc7hlMBFJCimOqbaMS+apdnJ/PnGIhZnJWuU2hj035mIBM1EY6p7+/p552QD85PiWJmXyqr8gR8ZnxK4iIRcVWMXrx6tpa3bzSVF6aEOJ2IogYtIyLjcHn5/rJ4Pz7fhTIjhlrJ88p0zq18ylyiBi0jI1La5OFrTziVF6Vx2Ubpf6pfMJUrgIhJUnT19nGvpZklWMgszErljUxGp8ZOP6Q7npc1CRf/diUhQWGs5cr6Np/ec4dUjtbjcHgCfk/cjex6hubt5xDT8gxcOBjrssKYWuIgEXGu3m9craqls6CI3zcHW5dk4Yqa3tBlMfRr+bKUELiIB1dPn4d/fraLfWj5dsoDV+alTHtNd1VpFfsrIYmzhtLRZqCiBi0hADC8+tWVpJrlp8T51l4xlOtPw5wL1gYuIX3n6Le95i0+d9hafWpaTMu3kDeG/tFmoKIGLiN/Utbn4+XtVvHW8geLMRBb4qfhUuC9tFirqQhERv/jj6Sb2nGwkPjaK60tzWJyV7NfnD+elzUJFCVxE/CIhNpqSnGSuXJI5pREmMn1K4CIyLT19Ht450cj8pDhW5aeyMm/gR4JHCVxEpqyyoZNdR2vp6OlT8akQUgIXEZ+53B7ePFbPkfNtpCfG8qWyAnLT4kMd1pylBC4yx8ykpkhtm4uKmnYuK07n0uJ05qn4VEjp6ovMIdOpKdLZ08dHF9oBWJiRyJ2bi7j84vlK3mFg0ha4McYB/B6I8x7/orX2vxpj0oHngCKgEviStbY5cKGKyExNpaaItZYjNW28eawea2FhRgKOmGhSHFoNPlz40oXSA3zGWtthjIkB3jLG/BrYBrxmrX3YGPMg8CDwQABjFZEZ8rWmSGu3m9eO1nKmsYs8Zzxbl2XhiIlWSdcwM+lnIDugw3s3xvtjgRuBp7zbnwK+EIgARcR/ClMLaXW1jtg2uqbIYPGpmlYXnylZwC3r83EmxqqkaxjyqRPLGBNtjCkH6oBXrbXvAlnW2hoA7+8FAYtSRPxiopoiHT19AMTNi+bTJZn82caFrC5IG6ocOLz7JcpE4Yx34nQ42VmxM5T/pDnNpwRurfVYa9cA+cClxpiVvp7AGHOPMWafMWZffX39NMMUEX8Yq6bI1y/7e7q78kYUnyrJTvlEX3dVaxWpjpETdVTSNbSmNIzQWttijNkNXAvUGmNyrLU1xpgcBlrnYz3mceBxgLKyMjvDeEVkhobXFKltc/G7I7U0tDeyJCuZrJTxi0+ppGv4mbQFbozJNMakeW/HA1cDFcArwHbvYduBlwMUo4gEwLunGvn5H8/i6vXw+dW5XFeaQ0Ls+G06lXQNP760wHOAp4wx0Qwk/Oettb80xuwBnjfG3A1UAbcEME4R8bPEuHksz03hU4vn+1R8arD7ZfgolLvX3q1RKCFkrA1er0ZZWZndt29f0M4nMltNZzhfT5+Ht080kJnkYFW+ik5FEmPMfmtt2ejtmkolEmGmM5zvdEMnP91zhoPVrbS73EGMVgJJtVBEIsxUZlN29w4Unzpa00ZGUiy3lhaQk6riU7OFErhIhJnKCu317T0cq23nsovSubRIxadmG72aIhFmstmUHT19VFxoGzg2I4E7NxVx+SIVn5qN9IqKRJjxhvPdtPQmDp9r5ek9lbx2tA6X2wNAsopPzVpK4CIRZqzZlF9d+w2On8/g1SO1ZCbFcdtlhVqXcg5QH7hIBBo+m9Ll9vDE26ex1sXVy7JYmZcyVL9EZjclcJEI1e5yk+yIwRETzVUlWeSmOdRdMseoC0Ukwnj6LXtPNfJ/364cKj61NDtZyXsOUgtcJIJcaHXx6tFaGtp7KMmeuPiUzH5K4CIRYu+pRvaeaiQpbh43rMllUWZSqEOSEFMCF4kQSXHzWJmbymYfi0/J7KcELhKmXG5v8ankOErz01iZl8rKPBWhko8pgYuEoVP1HbxeUUdHTx+XFWeEOhwJU0rgImGkq7ePNz+qp+JCO/OTYrm+tJDsVEeow5IwpQQuEkYa2ns5XtfBxkUZXFKUTnSUJuTI+JTARWZgOgsrjNbuclPd3M2ynBQKMxK4a3MxSXH605TJaSKPyDRNZ2GF4ay1HKpu5ek9Z3i94uPiU0re4iu9U0SmaSoLK4zW0tXLq0dqqW7upiA9gauXLdDQQJkyJXCRaZrKwgrDudwe/v2PVVgLW5dnsSJXxadkepTARaapMLWQ5u7moZY3jFxYYbQ2l5sUb/Gpq5dlkZOq4lMyM+oDF5mm8RZW2FaybcRxfZ5+3jnZwJNvV3KqvgOAJVkqPiUzpwQuMk1jLaywY+OOEf3fNa3d/Psfq3j3VBNLspK0oLD4lbpQRGZg+MIKo+052ci7pweKT31hbR7F8xODHJ3MdkrgIgGSEj+P0vxUNl08n7h5GmEi/qcELuInLreHt44PFJ9aXZDGitxUVuSq+JQEjhK4iB+crO/g9aN1dPb6XnzKH7M4ZW7Tl5giM9DV28evDtXwSvl5HLHRfOXSQjYumjyBz3QWpwioBS4yIw3tvZys6+DyRRmUTaH41ExmcYoMUgIXmaI2l5vqpm6W5w4Un7pzGsWnpjuLU2Q4JXARH1lrOVjdylsnGgC4KDMRR0z0tIpPTXUWp8hY1Acu4oPmzl5e2F/N6xV1ZKc4uP2yhTMqPuXrLE6RiSiBi0xisPhUQ0cPW5dnsW1dHqkJM5sG78ssTpHJqAtFZByt3W5S4weKT12zPIuctHi/1uqeaBaniC/UAhcZpc/TzzsnRhafWpyVrIUWJOzoHSkyzPmWbnYdraWxo5dlOSkqPiVhTQlc5rThsyFj+laQHn0pizLyuGltHkUqPiVhTl0oMmeNng3Z09/MoeZfsra4XclbIsKkLXBjTAHwNJAN9AOPW2t/ZIxJB54DioBK4EvW2ubAhSoytunWFHn+w5dwdSyhz8QRFd9JUWYUqUnt/OeJl1ifvzoIkYvMjC8t8D7g7621y4ANwF8bY5YDDwKvWWsXA69574sE1XRripyoa2fvsVh6XJl4+j+e/q7ZkBJJJm2BW2trgBrv7XZjzFEgD7gR2OI97ClgN/BAQKIUGcdUa4p09vTxxkd1HK/tYH5iCqkpJ8hO+7i7RLMhJZJMqQ/cGFMErAXeBbK8yX0wyS8Y5zH3GGP2GWP21dfXzzBckZGqWqtIdYysuT1RK7qps5fT9Z1sung+D1y9mW5bq9mQErF8TuDGmCTgP4C/s9a2+fo4a+3j1toya21ZZmbmdGIUGVdhaiGtrtYR20a3olu73Xx4fuCYgvQE7tpczKXF6azNXa3ZkBLRfBpGaIyJYSB5P2Ot3endXGuMybHW1hhjcoC6QAUpMp5tJdt4ZM8jwEDLu9XVSrOrmbvX3o21lgPVrbx9ogFjYFFmEo6YaBKHTcjRbEiJZJO2wI0xBvgJcNRa+4Nhu14Btntvbwde9n94IhMbr6ZIfnIJL+yr5o2KOnLTHNw2w+JTIuHIWGsnPsCYzcAfgEMMDCME+C8M9IM/DxQCVcAt1tqmiZ6rrKzM7tu3b6Yxi0zI5fbwk7dOE2UMVyyZz/KcFAbaISKRyRiz31pbNnq7L6NQ3gLGe/dfNdPARMA/60O2drlJTRgoPvUnK7LISY0f0V0iMttoJqaE3EzXh+zz9PP2iQaefKeSk97iUxcvSFbylllP73AJuZmsD3mupZtdR2pp6uxleW4KeWkqPiVzhxK4hNx014d850QDf6xsItkRw7Z1eSzMUP0SmVuUwCXkpro+pLUWYwxpCbGsLkhj06L5xM5Tb6DMPXrXS8j5uj6ky+3hN4cvcKB6YFLO8twUPr10gZK3zFl650vI+bI+5PHadp56p5KPLrTT29c/wbOJzB3qQpGwMN6MyI6ePt6oqONEXQcLUuK4aV0WC5IdIYhQJPwogUtYa+7s5UxjJ59aPJ91hU6iojQhR2SQEriEndYuN2ebu1iZlzpUfCohVm9VkdH0VyFho7/fcqC6hbdPNBAVZbh4wUDxKSVvkbHpL0PCQmNHD7uO1nK+xUXx/EQ+s2yBik+JTEIJXELO5fbw8/fOEmUM167MpiQ7WcWnRHygBC4hM7L4VDa5aQ51l4hMgcaBS9C5Pf384Xj9qOJTSUreIlOkvxgJqurmLnYdqaW5y83KvFQVnxKZASVw8ZvJanq/faKBP55uIjU+hi+uy6cwIyGE0YpEPnWhiF9MVNN7cNWn9MRY1i10cvuGhUreIn6gBC5+Mbymd5SJwhnvJDkmgx/ufoPysy0ALMtJ4colmSo+JeIn6kIRvxhe09taaOmIp6Y+i+budvr6J153VUSmRwlchsxkXcrBmt5JMRmcrUujtdMB0S1cenEvlxSlBzhykblJn2UFmPm6lIM1vevaO2nriiUluZqUtMPctvqGAEcuMncpgQswdh+20+FkZ8XOSR/b2uUmyrOQHRt3kOeMJzV9P4uyo/jm5TumvLK8iPhOXSgCTG9dyv5+ywdnW9hzsoHoqCju3LSCh7YoYYsEixK4AFNfl7Kho4ddR2qpaXVxUWYinylR8SmRYFMXigC+r0sJA8WnnnvvLC3dbj67KpsbVueS7IgJQdQic5ta4AJ8vC7l8FEod6+9e0QfdnNnL87EWBwx0Vy7MpucVBWfEgkl/fXJkPHWpXR7+tlzspH3q5r5/OpcFmUmsSgzKQQRishwSuAyobNNXew6WktLl5vSfBWfEgknSuAyrreON/BeZRNpCTHcvD6fgnTVLxEJJ0rg8gnWWowxzE+OZf1CJxsXZRATre+7RcKNErgM6ert482P6slOdbC20ElJdgol2aGOSkTGowQ+y0ynnom1lo9q29n9UT29ff1kJscFKVoRmQl9Lp5FplPPpN3l5pUD5/n1oQukxcfwp5cVUqbiUyIRQS3wWWR4PRNg6PfOip3jtsJbutxUN3dzxZJM1hakERWl1eBFIoVa4LNIVWsVqY7UEdvGqmfS0tXLoepWAArSE7hrUzHrFzqVvEUijFrgs8hk9UwGik81886JRuZFR7E4KwlHTDTxsaphIhKJ1AKfRSaqZ1Lf3sPP3zvL7481UJiRwO0bClV8SiTCTZrAjTFPGGPqjDGHh21LN8a8aow57v3tnOg5JDgG65k4451Ut1XjjHeyY+MOlmSs4Pl9Z2l3ubmuNEfFp0RmCTO4Yvi4BxhzBdABPG2tXend9j2gyVr7sDHmQcBprX1gspOVlZXZffv2+SFs8cVg8SmAU/Ud5KTGq7tEJAIZY/Zba8tGb5+0BW6t/T3QNGrzjcBT3ttPAV+YaYDiP719/bx5rJ6n9lRysr4DgIsyk5S8RWaZ6X6JmWWtrQGw1tYYYxb4MSaZgbNNXbx6pJbWbjerC1LJd6r4lMhsFfBRKMaYe4B7AAoLx17dRfzjD8fr2VfZjFPFp0TmhOmOQqk1xuQAeH/XjXegtfZxa22ZtbYsMzNzmqeTiQx+j5GZHEdZkZPbNixU8haZA6abwF8Btntvbwde9k84MhVdvX386lANH5xtAaAkO4VPLc5U5UCROWLSLhRjzLPAFmC+MaYa+K/Aw8Dzxpi7gSrglkAGKSNZa6m4MFB8yu3pJytFxadE5qJJE7i19ivj7LrKz7GID9pcbl4/Wsfphk5y0xxcvSyLjCQlcJG5SFPpI0xbt5tzLd1sWZrJ6nwVnxKZy5TAI0BzZy9nm7sozU8j35nA3ZuLNQ1eRJTAw9HgogxnWqpw2OWkR11GQVouS7KSccREK3mLCKBiVmFncFGGmtZOutvWcepCLPvrf8Oa4nYlbhEZQQk8zOys2ElKbAb1DRfT55nHsoIuluZ18JtTvwh1aCISZtSFEkaaOnupaq0iPyWfmOwmEh29zIu29NtPLsogIqIEPoHpLBA8Hb19/bx9soEDZ1tIiV5Cq6sGZ+LHH46GL8ogIjJIXSjjmM4CwdNxprGTn+49w4GzLazOT+PP1nx23EUZRESGUwt8HNNZIHg4X1rvvz9Wz/4zzaQnxnJLWQF5afHAAnbM2zHisXevvTsgLX8RiWxK4OMY7IsebqwFgscy2Hp3OpwjWu87Nu6gNLsUay3GGLJSHFxanM5lxenMG1a/pDS7VAlbRCalBD6OyRYInsh4rffnDv+Cqrr55KbFs67QydLsZJaSHJh/gIjMeuoDH8dECwRPpqq1ilRH6tB9a8HTm8PeY7Gcru9kklXsRER8ogQ+jvEWCPala6MwtZBWVysAPe5oTtVkcPx8AtkpSdy2YSHrF2oNaBGZOXWhTGC6fdHbSrbxyJ5HAIi2mTS0e4hPquT+q+4k3bvIsIjITKkFHgD5ySXcWHwfzngnLe5TrL+4le9svYvVOatDHZqIzCJqgfuRp9+y/0wze081EjsvnQc3fVv1S0QkYJTA/aSuzcXvjtRS397D4qwkPr10gZK3iASUErgfuNweXthfTUy04fOrc7h4gYYGikjgKYHPQGNHDxlJcThiovncqhxyUh1qdYtI0OhLzGno6fPwRkUdT+85w4m6DgCK5ycqeYtIUKkFPkWVDZ3sOlpLR08fawvTKExPCHVIIjJHKYFPwZvH6nn/TDMZSbF8aVUBuWnxoQ5JROawWZ3A/VHP23rnvRtjyEl1cFlxOpeOKj4lIhIKszYL+aOed0dPH788WMP7VS0ALMlK5vKL5yt5i0hYmLUt8JnU87bW8uH5Nn5/vB6Px5LnVFeJiISfWZvAp1vPu7Xbza4jtVQ1dZHnjGfrsiycql8iImFo1ibw6dbz7ujp40Kbi8+ULKA0PxVjTKBDFRGZllnbmTuVet6NHT2Un20BIC8tnrs3F7O6IE3JW0TC2qxN4L7U8/b0W/aeauSZd6t491QjLrcHQBNyRCQizNouFJi4nnett/hUQ3sPS7OT2bI0U4lbRCLKrE7g43G5Pby4v5rY6ChuWJPLosykUIckIjJlcyqBN3T0kJEYiyMmmutW5ZCt4lMiEsFmbR/4cD19Hl47WstP95zhZH0nAEUqPiUiEW7Wt8BPN3Tymrf41LqFThWfEpFZY1Yn8N0f1fFBVQvzk2K5rrSAnFTNqBSR2SPsE/hUC1INLz6VmxZP3LxoLilyqn6JiMw6YZ3VplqQqt3l5pUD53m/qhkYKD61cVGGkreIzEphndmGF6SKMlE44504HU52VuwccZy1lkPVrTy95wxnm7qIjgrrf5aIiF/MqAvFGHMt8CMgGvg/1tqH/RKVly8FqVq73Lx6tJazTV3kO+PZujyLtAQVnxKR2W/aCdwYEw08BmwFqoH3jDGvWGuP+Cs4XwpSdfT2Udfu4uplWazMS1H9EhGZM2bS13ApcMJae8pa2wv8HLjRP2ENGK8g1WcKb+QDbz/3YPGpVaocKCJzzEwSeB5wdtj9au+2EYwx9xhj9hlj9tXX10/pBKMLUqU6nPxJ/r2Un07ij6ebhopPxc3ThBwRmXtm0gc+VnPXfmKDtY8DjwOUlZV9Yv9kBgtSXWh18eqRC9S19FKSncSVKj4lInPcTBJ4NVAw7H4+cH5m4YzN5fbwH+9XEzdPxadERAbNJIG/Byw2xhQD54AvA3/ql6hGccREc31pDlkpKj4lIjJo2gncWttnjLkX+C0DwwifsNZ+6LfIRlmYkRiopxYRiUgzGgdurf0V8Cs/xSIiIlOgKYsiIhFKCVxEJEIpgYuIRCglcBGRCKUELiISoZTARUQilBK4iEiEMoNLkAXlZMbUA2em+fD5QIMfw/EXxTU1imtqFNfUhGtcMLPYFlprM0dvDGoCnwljzD5rbVmo4xhNcU2N4poaxTU14RoXBCY2daGIiEQoJXARkQgVSQn88VAHMA7FNTWKa2oU19SEa1wQgNgipg9cRERGiqQWuIiIDKMELiISocIugRtjrjXGfGSMOWGMeXCM/cYY86h3/0FjzLogxFRgjHnDGHPUGPOhMeZvxzhmizGm1RhT7v35x0DH5T1vpTHmkPec+8bYH4rrtXTYdSg3xrQZY/5u1DFBuV7GmCeMMXXGmMPDtqUbY141xhz3/naO89gJ34sBiOu/G2MqvK/TS8aYtHEeO+FrHoC4HjLGnBv2Wn1unMcG+3o9NyymSmNM+TiPDeT1GjM3BO09Zq0Nmx8GVvY5CVwExAIHgOWjjvkc8GsGFlXeALwbhLhygHXe28nAsTHi2gL8MgTXrBKYP8H+oF+vMV7TCwxMRAj69QKuANYBh4dt+x7woPf2g8B3p/NeDEBc1wDzvLe/O1ZcvrzmAYjrIWCHD69zUK/XqP3fB/4xBNdrzNwQrPdYuLXALwVOWGtPWWt7gZ8DN4465kbgaTtgL5BmjMkJZFDW2hpr7fve2+3AUSAvkOf0o6Bfr1GuAk5aa6c7A3dGrLW/B5pGbb4ReMp7+yngC2M81Jf3ol/jstb+zlrb5727l4GFwoNqnOvli6Bfr0HGGAN8CXjWX+fz1QS5ISjvsXBL4HnA2WH3q/lkovTlmIAxxhQBa4F3x9i90RhzwBjza2PMiiCFZIHfGWP2G2PuGWN/SK8XA4tdj/eHFYrrBZBlra2BgT9AYMEYx4T6ut3FwCensUz2mgfCvd6unSfG6Q4I5fX6FFBrrT0+zv6gXK9RuSEo77FwS+BmjG2jxzn6ckxAGGOSgP8A/s5a2zZq9/sMdBOsBv4n8ItgxARsstauAz4L/LUx5opR+0N5vWKBG4AXxtgdquvlq1Bet38A+oBnxjlkstfc334MLALWADUMdFeMFrLrBXyFiVvfAb9ek+SGcR82xrYpXbNwS+DVQMGw+/nA+Wkc43fGmBgGXqBnrLU7R++31rZZazu8t38FxBhj5gc6Lmvtee/vOuAlBj6WDReS6+X1WeB9a23t6B2hul5etYPdSN7fdWMcE6r32XbgeuA26+0oHc2H19yvrLW11lqPtbYf+N/jnC9U12sesA14brxjAn29xskNQXmPhVsCfw9YbIwp9rbevgy8MuqYV4A/946u2AC0Dn5UCRRvH9tPgKPW2h+Mc0y29ziMMZcycG0bAxxXojEmefA2A1+CHR51WNCv1zDjtoxCcb2GeQXY7r29HXh5jGN8eS/6lTHmWuAB4AZrbdc4x/jymvs7ruHfmdw0zvmCfr28rgYqrLXVY+0M9PWaIDcE5z0WiG9mZ/it7ucY+Cb3JPAP3m1fBb7qvW2Ax7z7DwFlQYhpMwMfbQ4C5d6fz42K617gQwa+Sd4LXB6EuC7ynu+A99xhcb28501gICGnDtsW9OvFwH8gNYCbgRbP3UAG8Bpw3Ps73XtsLvCrid6LAY7rBAN9ooPvsf81Oq7xXvMAx/VT73vnIAMJJiccrpd3+5OD76lhxwbzeo2XG4LyHtNUehGRCBVuXSgiIuIjJXARkQilBC4iEqGUwEVEIpQSuIhIhFICFxGJUErgIiIR6v8Dyy0KdxTxK5UAAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "plt.plot(x_train,y_train,\"go\",label=\"True Data\",alpha=0.5)\n",
    "plt.plot(x_train,predicted,\"--\",label=\"predictions\",alpha=0.5)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}